{
  "best_global_step": 850,
  "best_metric": 5.129420280456543,
  "best_model_checkpoint": "./cultural_vlm_working\\checkpoint-850",
  "epoch": 2.7777777777777777,
  "eval_steps": 50,
  "global_step": 850,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.016339869281045753,
      "grad_norm": 38.26896286010742,
      "learning_rate": 4.0000000000000003e-07,
      "loss": 21.5222,
      "step": 5
    },
    {
      "epoch": 0.032679738562091505,
      "grad_norm": 14.553839683532715,
      "learning_rate": 9.000000000000001e-07,
      "loss": 21.5069,
      "step": 10
    },
    {
      "epoch": 0.049019607843137254,
      "grad_norm": 38.59209442138672,
      "learning_rate": 1.4000000000000001e-06,
      "loss": 21.3123,
      "step": 15
    },
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 18.0140380859375,
      "learning_rate": 1.9000000000000002e-06,
      "loss": 21.2238,
      "step": 20
    },
    {
      "epoch": 0.08169934640522876,
      "grad_norm": 15.129743576049805,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 21.207,
      "step": 25
    },
    {
      "epoch": 0.09803921568627451,
      "grad_norm": 55.5308952331543,
      "learning_rate": 2.9e-06,
      "loss": 21.0261,
      "step": 30
    },
    {
      "epoch": 0.11437908496732026,
      "grad_norm": 14.212453842163086,
      "learning_rate": 3.4000000000000005e-06,
      "loss": 21.0572,
      "step": 35
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 59.64015197753906,
      "learning_rate": 3.900000000000001e-06,
      "loss": 20.8219,
      "step": 40
    },
    {
      "epoch": 0.14705882352941177,
      "grad_norm": 65.4885025024414,
      "learning_rate": 4.4e-06,
      "loss": 20.8758,
      "step": 45
    },
    {
      "epoch": 0.16339869281045752,
      "grad_norm": 77.038818359375,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 20.6391,
      "step": 50
    },
    {
      "epoch": 0.16339869281045752,
      "eval_loss": 5.3148956298828125,
      "eval_runtime": 34.4437,
      "eval_samples_per_second": 3.948,
      "eval_steps_per_second": 0.494,
      "step": 50
    },
    {
      "epoch": 0.17973856209150327,
      "grad_norm": 161.172119140625,
      "learning_rate": 5.400000000000001e-06,
      "loss": 20.8137,
      "step": 55
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 92.20557403564453,
      "learning_rate": 5.9e-06,
      "loss": 20.7722,
      "step": 60
    },
    {
      "epoch": 0.21241830065359477,
      "grad_norm": 194.28199768066406,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 20.9152,
      "step": 65
    },
    {
      "epoch": 0.22875816993464052,
      "grad_norm": 12.823917388916016,
      "learning_rate": 6.9e-06,
      "loss": 20.7067,
      "step": 70
    },
    {
      "epoch": 0.24509803921568626,
      "grad_norm": 100.21053314208984,
      "learning_rate": 7.4e-06,
      "loss": 20.7349,
      "step": 75
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 114.09513854980469,
      "learning_rate": 7.9e-06,
      "loss": 20.5388,
      "step": 80
    },
    {
      "epoch": 0.2777777777777778,
      "grad_norm": 80.38729858398438,
      "learning_rate": 8.400000000000001e-06,
      "loss": 20.5389,
      "step": 85
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 15.981563568115234,
      "learning_rate": 8.900000000000001e-06,
      "loss": 20.5069,
      "step": 90
    },
    {
      "epoch": 0.3104575163398693,
      "grad_norm": 41.93463134765625,
      "learning_rate": 9.4e-06,
      "loss": 20.5639,
      "step": 95
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 6.414069652557373,
      "learning_rate": 9.9e-06,
      "loss": 20.5026,
      "step": 100
    },
    {
      "epoch": 0.32679738562091504,
      "eval_loss": 5.256805419921875,
      "eval_runtime": 33.9866,
      "eval_samples_per_second": 4.002,
      "eval_steps_per_second": 0.5,
      "step": 100
    },
    {
      "epoch": 0.3431372549019608,
      "grad_norm": 34.00313949584961,
      "learning_rate": 1.04e-05,
      "loss": 20.521,
      "step": 105
    },
    {
      "epoch": 0.35947712418300654,
      "grad_norm": 8.502431869506836,
      "learning_rate": 1.0900000000000002e-05,
      "loss": 20.6023,
      "step": 110
    },
    {
      "epoch": 0.3758169934640523,
      "grad_norm": 72.1801528930664,
      "learning_rate": 1.14e-05,
      "loss": 20.565,
      "step": 115
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 7.322787284851074,
      "learning_rate": 1.1900000000000001e-05,
      "loss": 20.4804,
      "step": 120
    },
    {
      "epoch": 0.4084967320261438,
      "grad_norm": 77.08651733398438,
      "learning_rate": 1.2400000000000002e-05,
      "loss": 20.404,
      "step": 125
    },
    {
      "epoch": 0.42483660130718953,
      "grad_norm": 114.14712524414062,
      "learning_rate": 1.2900000000000002e-05,
      "loss": 20.5088,
      "step": 130
    },
    {
      "epoch": 0.4411764705882353,
      "grad_norm": 12.71867847442627,
      "learning_rate": 1.3400000000000002e-05,
      "loss": 20.4275,
      "step": 135
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 13.894290924072266,
      "learning_rate": 1.39e-05,
      "loss": 20.481,
      "step": 140
    },
    {
      "epoch": 0.4738562091503268,
      "grad_norm": 97.36418151855469,
      "learning_rate": 1.4400000000000001e-05,
      "loss": 20.4419,
      "step": 145
    },
    {
      "epoch": 0.49019607843137253,
      "grad_norm": 21.132099151611328,
      "learning_rate": 1.4900000000000001e-05,
      "loss": 20.3839,
      "step": 150
    },
    {
      "epoch": 0.49019607843137253,
      "eval_loss": 5.2232666015625,
      "eval_runtime": 33.682,
      "eval_samples_per_second": 4.038,
      "eval_steps_per_second": 0.505,
      "step": 150
    },
    {
      "epoch": 0.5065359477124183,
      "grad_norm": 4.782593250274658,
      "learning_rate": 1.54e-05,
      "loss": 20.3356,
      "step": 155
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 7.651669502258301,
      "learning_rate": 1.5900000000000004e-05,
      "loss": 20.2327,
      "step": 160
    },
    {
      "epoch": 0.5392156862745098,
      "grad_norm": 67.72860717773438,
      "learning_rate": 1.64e-05,
      "loss": 20.2716,
      "step": 165
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 5.029348850250244,
      "learning_rate": 1.69e-05,
      "loss": 20.3602,
      "step": 170
    },
    {
      "epoch": 0.5718954248366013,
      "grad_norm": 6.497302532196045,
      "learning_rate": 1.7400000000000003e-05,
      "loss": 20.4088,
      "step": 175
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 6.576371192932129,
      "learning_rate": 1.79e-05,
      "loss": 20.5499,
      "step": 180
    },
    {
      "epoch": 0.6045751633986928,
      "grad_norm": 13.053315162658691,
      "learning_rate": 1.8400000000000003e-05,
      "loss": 20.1783,
      "step": 185
    },
    {
      "epoch": 0.6209150326797386,
      "grad_norm": 40.93875503540039,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 20.2841,
      "step": 190
    },
    {
      "epoch": 0.6372549019607843,
      "grad_norm": 5.062676906585693,
      "learning_rate": 1.94e-05,
      "loss": 20.2522,
      "step": 195
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 5.72667932510376,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 20.1485,
      "step": 200
    },
    {
      "epoch": 0.6535947712418301,
      "eval_loss": 5.186253070831299,
      "eval_runtime": 33.8114,
      "eval_samples_per_second": 4.022,
      "eval_steps_per_second": 0.503,
      "step": 200
    },
    {
      "epoch": 0.6699346405228758,
      "grad_norm": 8.893180847167969,
      "learning_rate": 1.9999903471186634e-05,
      "loss": 20.2571,
      "step": 205
    },
    {
      "epoch": 0.6862745098039216,
      "grad_norm": 6.275423526763916,
      "learning_rate": 1.9999511326076227e-05,
      "loss": 20.3326,
      "step": 210
    },
    {
      "epoch": 0.7026143790849673,
      "grad_norm": 5.950165271759033,
      "learning_rate": 1.999881754343799e-05,
      "loss": 20.391,
      "step": 215
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 6.285647869110107,
      "learning_rate": 1.9997822144200035e-05,
      "loss": 20.2087,
      "step": 220
    },
    {
      "epoch": 0.7352941176470589,
      "grad_norm": 6.340970516204834,
      "learning_rate": 1.9996525158388804e-05,
      "loss": 20.2168,
      "step": 225
    },
    {
      "epoch": 0.7516339869281046,
      "grad_norm": 5.483854293823242,
      "learning_rate": 1.999492662512817e-05,
      "loss": 20.1133,
      "step": 230
    },
    {
      "epoch": 0.7679738562091504,
      "grad_norm": 4.751608371734619,
      "learning_rate": 1.999302659263825e-05,
      "loss": 20.1599,
      "step": 235
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 4.94934606552124,
      "learning_rate": 1.9990825118233958e-05,
      "loss": 20.1238,
      "step": 240
    },
    {
      "epoch": 0.8006535947712419,
      "grad_norm": 5.156955242156982,
      "learning_rate": 1.998832226832327e-05,
      "loss": 20.2052,
      "step": 245
    },
    {
      "epoch": 0.8169934640522876,
      "grad_norm": 5.369345188140869,
      "learning_rate": 1.998551811840521e-05,
      "loss": 20.2557,
      "step": 250
    },
    {
      "epoch": 0.8169934640522876,
      "eval_loss": 5.167814254760742,
      "eval_runtime": 33.6263,
      "eval_samples_per_second": 4.044,
      "eval_steps_per_second": 0.506,
      "step": 250
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 8.00222396850586,
      "learning_rate": 1.998241275306761e-05,
      "loss": 20.1667,
      "step": 255
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 5.749771595001221,
      "learning_rate": 1.9979006265984516e-05,
      "loss": 20.2071,
      "step": 260
    },
    {
      "epoch": 0.8660130718954249,
      "grad_norm": 9.824156761169434,
      "learning_rate": 1.9975298759913382e-05,
      "loss": 20.0525,
      "step": 265
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 5.066336631774902,
      "learning_rate": 1.997129034669197e-05,
      "loss": 20.1366,
      "step": 270
    },
    {
      "epoch": 0.8986928104575164,
      "grad_norm": 5.567432880401611,
      "learning_rate": 1.9966981147234975e-05,
      "loss": 20.1583,
      "step": 275
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 3.518766403198242,
      "learning_rate": 1.9962371291530375e-05,
      "loss": 20.1634,
      "step": 280
    },
    {
      "epoch": 0.9313725490196079,
      "grad_norm": 6.2730712890625,
      "learning_rate": 1.9957460918635513e-05,
      "loss": 20.1267,
      "step": 285
    },
    {
      "epoch": 0.9477124183006536,
      "grad_norm": 6.248128890991211,
      "learning_rate": 1.9952250176672904e-05,
      "loss": 20.124,
      "step": 290
    },
    {
      "epoch": 0.9640522875816994,
      "grad_norm": 7.347362041473389,
      "learning_rate": 1.994673922282576e-05,
      "loss": 20.0455,
      "step": 295
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 48.801673889160156,
      "learning_rate": 1.9940928223333254e-05,
      "loss": 20.2146,
      "step": 300
    },
    {
      "epoch": 0.9803921568627451,
      "eval_loss": 5.152705669403076,
      "eval_runtime": 33.6908,
      "eval_samples_per_second": 4.037,
      "eval_steps_per_second": 0.505,
      "step": 300
    },
    {
      "epoch": 0.9967320261437909,
      "grad_norm": 5.199045181274414,
      "learning_rate": 1.99348173534855e-05,
      "loss": 20.1672,
      "step": 305
    },
    {
      "epoch": 1.0130718954248366,
      "grad_norm": 4.600134372711182,
      "learning_rate": 1.9928406797618285e-05,
      "loss": 20.135,
      "step": 310
    },
    {
      "epoch": 1.0294117647058822,
      "grad_norm": 5.479318141937256,
      "learning_rate": 1.992169674910747e-05,
      "loss": 20.1584,
      "step": 315
    },
    {
      "epoch": 1.0457516339869282,
      "grad_norm": 6.460124492645264,
      "learning_rate": 1.9914687410363196e-05,
      "loss": 20.0922,
      "step": 320
    },
    {
      "epoch": 1.0620915032679739,
      "grad_norm": 5.794046401977539,
      "learning_rate": 1.9907378992823755e-05,
      "loss": 20.148,
      "step": 325
    },
    {
      "epoch": 1.0784313725490196,
      "grad_norm": 3.8983561992645264,
      "learning_rate": 1.9899771716949218e-05,
      "loss": 20.079,
      "step": 330
    },
    {
      "epoch": 1.0947712418300655,
      "grad_norm": 4.643613338470459,
      "learning_rate": 1.9891865812214793e-05,
      "loss": 19.9603,
      "step": 335
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 5.630549907684326,
      "learning_rate": 1.9883661517103884e-05,
      "loss": 20.0925,
      "step": 340
    },
    {
      "epoch": 1.1274509803921569,
      "grad_norm": 5.30294942855835,
      "learning_rate": 1.9875159079100917e-05,
      "loss": 20.0146,
      "step": 345
    },
    {
      "epoch": 1.1437908496732025,
      "grad_norm": 5.252014636993408,
      "learning_rate": 1.9866358754683864e-05,
      "loss": 20.1395,
      "step": 350
    },
    {
      "epoch": 1.1437908496732025,
      "eval_loss": 5.14545202255249,
      "eval_runtime": 33.6069,
      "eval_samples_per_second": 4.047,
      "eval_steps_per_second": 0.506,
      "step": 350
    },
    {
      "epoch": 1.1601307189542482,
      "grad_norm": 5.0852813720703125,
      "learning_rate": 1.985726080931651e-05,
      "loss": 20.0854,
      "step": 355
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 5.807145595550537,
      "learning_rate": 1.9847865517440438e-05,
      "loss": 20.116,
      "step": 360
    },
    {
      "epoch": 1.1928104575163399,
      "grad_norm": 6.906466960906982,
      "learning_rate": 1.983817316246676e-05,
      "loss": 20.0965,
      "step": 365
    },
    {
      "epoch": 1.2091503267973855,
      "grad_norm": 5.250594615936279,
      "learning_rate": 1.9828184036767556e-05,
      "loss": 20.0758,
      "step": 370
    },
    {
      "epoch": 1.2254901960784315,
      "grad_norm": 4.192443370819092,
      "learning_rate": 1.9817898441667082e-05,
      "loss": 20.05,
      "step": 375
    },
    {
      "epoch": 1.2418300653594772,
      "grad_norm": 5.576468467712402,
      "learning_rate": 1.9807316687432637e-05,
      "loss": 20.005,
      "step": 380
    },
    {
      "epoch": 1.2581699346405228,
      "grad_norm": 4.258819103240967,
      "learning_rate": 1.9796439093265245e-05,
      "loss": 19.936,
      "step": 385
    },
    {
      "epoch": 1.2745098039215685,
      "grad_norm": 4.67460298538208,
      "learning_rate": 1.978526598729e-05,
      "loss": 20.1677,
      "step": 390
    },
    {
      "epoch": 1.2908496732026145,
      "grad_norm": 6.1327691078186035,
      "learning_rate": 1.9773797706546176e-05,
      "loss": 20.0663,
      "step": 395
    },
    {
      "epoch": 1.3071895424836601,
      "grad_norm": 3.7558279037475586,
      "learning_rate": 1.9762034596977066e-05,
      "loss": 19.9031,
      "step": 400
    },
    {
      "epoch": 1.3071895424836601,
      "eval_loss": 5.139065742492676,
      "eval_runtime": 33.6885,
      "eval_samples_per_second": 4.037,
      "eval_steps_per_second": 0.505,
      "step": 400
    },
    {
      "epoch": 1.3235294117647058,
      "grad_norm": 7.098148345947266,
      "learning_rate": 1.9749977013419536e-05,
      "loss": 20.08,
      "step": 405
    },
    {
      "epoch": 1.3398692810457518,
      "grad_norm": 2.3441622257232666,
      "learning_rate": 1.9737625319593338e-05,
      "loss": 20.0416,
      "step": 410
    },
    {
      "epoch": 1.3562091503267975,
      "grad_norm": 7.012580871582031,
      "learning_rate": 1.972497988809011e-05,
      "loss": 20.0398,
      "step": 415
    },
    {
      "epoch": 1.3725490196078431,
      "grad_norm": 5.718914985656738,
      "learning_rate": 1.971204110036216e-05,
      "loss": 20.0089,
      "step": 420
    },
    {
      "epoch": 1.3888888888888888,
      "grad_norm": 6.407711505889893,
      "learning_rate": 1.9698809346710965e-05,
      "loss": 20.0476,
      "step": 425
    },
    {
      "epoch": 1.4052287581699345,
      "grad_norm": 3.751487970352173,
      "learning_rate": 1.968528502627537e-05,
      "loss": 20.0977,
      "step": 430
    },
    {
      "epoch": 1.4215686274509804,
      "grad_norm": 5.3491058349609375,
      "learning_rate": 1.9671468547019575e-05,
      "loss": 20.0833,
      "step": 435
    },
    {
      "epoch": 1.4379084967320261,
      "grad_norm": 5.0723700523376465,
      "learning_rate": 1.96573603257208e-05,
      "loss": 20.0248,
      "step": 440
    },
    {
      "epoch": 1.4542483660130718,
      "grad_norm": 5.068697929382324,
      "learning_rate": 1.964296078795675e-05,
      "loss": 20.0646,
      "step": 445
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 4.390775680541992,
      "learning_rate": 1.962827036809275e-05,
      "loss": 19.9241,
      "step": 450
    },
    {
      "epoch": 1.4705882352941178,
      "eval_loss": 5.14285135269165,
      "eval_runtime": 33.6785,
      "eval_samples_per_second": 4.038,
      "eval_steps_per_second": 0.505,
      "step": 450
    },
    {
      "epoch": 1.4869281045751634,
      "grad_norm": 5.8060784339904785,
      "learning_rate": 1.9613289509268647e-05,
      "loss": 20.002,
      "step": 455
    },
    {
      "epoch": 1.5032679738562091,
      "grad_norm": 5.720840930938721,
      "learning_rate": 1.9598018663385437e-05,
      "loss": 19.9391,
      "step": 460
    },
    {
      "epoch": 1.5196078431372548,
      "grad_norm": 4.700438022613525,
      "learning_rate": 1.9582458291091664e-05,
      "loss": 19.8018,
      "step": 465
    },
    {
      "epoch": 1.5359477124183005,
      "grad_norm": 4.982049465179443,
      "learning_rate": 1.956660886176948e-05,
      "loss": 19.9071,
      "step": 470
    },
    {
      "epoch": 1.5522875816993464,
      "grad_norm": 7.097657680511475,
      "learning_rate": 1.955047085352052e-05,
      "loss": 20.0212,
      "step": 475
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 6.132114410400391,
      "learning_rate": 1.953404475315146e-05,
      "loss": 20.057,
      "step": 480
    },
    {
      "epoch": 1.584967320261438,
      "grad_norm": 6.34305477142334,
      "learning_rate": 1.9517331056159353e-05,
      "loss": 19.9262,
      "step": 485
    },
    {
      "epoch": 1.6013071895424837,
      "grad_norm": 6.554078578948975,
      "learning_rate": 1.950033026671665e-05,
      "loss": 19.9403,
      "step": 490
    },
    {
      "epoch": 1.6176470588235294,
      "grad_norm": 3.5831761360168457,
      "learning_rate": 1.9483042897656032e-05,
      "loss": 19.8551,
      "step": 495
    },
    {
      "epoch": 1.6339869281045751,
      "grad_norm": 5.068871974945068,
      "learning_rate": 1.94654694704549e-05,
      "loss": 19.9741,
      "step": 500
    },
    {
      "epoch": 1.6339869281045751,
      "eval_loss": 5.142055511474609,
      "eval_runtime": 33.6925,
      "eval_samples_per_second": 4.037,
      "eval_steps_per_second": 0.505,
      "step": 500
    },
    {
      "epoch": 1.6503267973856208,
      "grad_norm": 6.045853614807129,
      "learning_rate": 1.944761051521968e-05,
      "loss": 19.9321,
      "step": 505
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 4.967005729675293,
      "learning_rate": 1.94294665706698e-05,
      "loss": 20.0652,
      "step": 510
    },
    {
      "epoch": 1.6830065359477124,
      "grad_norm": 4.294905185699463,
      "learning_rate": 1.941103818412147e-05,
      "loss": 19.9015,
      "step": 515
    },
    {
      "epoch": 1.6993464052287581,
      "grad_norm": 5.494741439819336,
      "learning_rate": 1.9392325911471154e-05,
      "loss": 20.0609,
      "step": 520
    },
    {
      "epoch": 1.715686274509804,
      "grad_norm": 6.369626045227051,
      "learning_rate": 1.9373330317178797e-05,
      "loss": 20.126,
      "step": 525
    },
    {
      "epoch": 1.7320261437908497,
      "grad_norm": 6.590451717376709,
      "learning_rate": 1.935405197425081e-05,
      "loss": 19.9955,
      "step": 530
    },
    {
      "epoch": 1.7483660130718954,
      "grad_norm": 5.64064884185791,
      "learning_rate": 1.933449146422278e-05,
      "loss": 20.0338,
      "step": 535
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 5.716353893280029,
      "learning_rate": 1.9314649377141935e-05,
      "loss": 20.0079,
      "step": 540
    },
    {
      "epoch": 1.7810457516339868,
      "grad_norm": 6.537838459014893,
      "learning_rate": 1.929452631154933e-05,
      "loss": 19.9883,
      "step": 545
    },
    {
      "epoch": 1.7973856209150327,
      "grad_norm": 6.780081272125244,
      "learning_rate": 1.9274122874461808e-05,
      "loss": 19.8853,
      "step": 550
    },
    {
      "epoch": 1.7973856209150327,
      "eval_loss": 5.133040428161621,
      "eval_runtime": 33.6863,
      "eval_samples_per_second": 4.037,
      "eval_steps_per_second": 0.505,
      "step": 550
    },
    {
      "epoch": 1.8137254901960784,
      "grad_norm": 7.432119846343994,
      "learning_rate": 1.9253439681353673e-05,
      "loss": 20.1302,
      "step": 555
    },
    {
      "epoch": 1.8300653594771243,
      "grad_norm": 4.031381130218506,
      "learning_rate": 1.923247735613814e-05,
      "loss": 20.05,
      "step": 560
    },
    {
      "epoch": 1.84640522875817,
      "grad_norm": 5.203853130340576,
      "learning_rate": 1.92112365311485e-05,
      "loss": 20.0474,
      "step": 565
    },
    {
      "epoch": 1.8627450980392157,
      "grad_norm": 3.734973907470703,
      "learning_rate": 1.918971784711907e-05,
      "loss": 19.897,
      "step": 570
    },
    {
      "epoch": 1.8790849673202614,
      "grad_norm": 5.472614288330078,
      "learning_rate": 1.9167921953165827e-05,
      "loss": 20.0045,
      "step": 575
    },
    {
      "epoch": 1.8954248366013071,
      "grad_norm": 5.719069480895996,
      "learning_rate": 1.9145849506766856e-05,
      "loss": 19.9398,
      "step": 580
    },
    {
      "epoch": 1.9117647058823528,
      "grad_norm": 4.3435750007629395,
      "learning_rate": 1.9123501173742514e-05,
      "loss": 19.9527,
      "step": 585
    },
    {
      "epoch": 1.9281045751633987,
      "grad_norm": 5.0592498779296875,
      "learning_rate": 1.9100877628235337e-05,
      "loss": 20.011,
      "step": 590
    },
    {
      "epoch": 1.9444444444444444,
      "grad_norm": 5.334160327911377,
      "learning_rate": 1.9077979552689708e-05,
      "loss": 19.9951,
      "step": 595
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 5.9663872718811035,
      "learning_rate": 1.9054807637831268e-05,
      "loss": 20.0482,
      "step": 600
    },
    {
      "epoch": 1.9607843137254903,
      "eval_loss": 5.1385321617126465,
      "eval_runtime": 33.6224,
      "eval_samples_per_second": 4.045,
      "eval_steps_per_second": 0.506,
      "step": 600
    },
    {
      "epoch": 1.977124183006536,
      "grad_norm": 4.633193016052246,
      "learning_rate": 1.903136258264609e-05,
      "loss": 19.9521,
      "step": 605
    },
    {
      "epoch": 1.9934640522875817,
      "grad_norm": 5.208354473114014,
      "learning_rate": 1.9007645094359576e-05,
      "loss": 19.969,
      "step": 610
    },
    {
      "epoch": 2.0098039215686274,
      "grad_norm": 4.677134037017822,
      "learning_rate": 1.898365588841515e-05,
      "loss": 19.9351,
      "step": 615
    },
    {
      "epoch": 2.026143790849673,
      "grad_norm": 6.793292999267578,
      "learning_rate": 1.8959395688452648e-05,
      "loss": 20.0349,
      "step": 620
    },
    {
      "epoch": 2.042483660130719,
      "grad_norm": 4.798228740692139,
      "learning_rate": 1.8934865226286507e-05,
      "loss": 20.0649,
      "step": 625
    },
    {
      "epoch": 2.0588235294117645,
      "grad_norm": 4.840968608856201,
      "learning_rate": 1.891006524188368e-05,
      "loss": 19.9547,
      "step": 630
    },
    {
      "epoch": 2.0751633986928106,
      "grad_norm": 4.045525550842285,
      "learning_rate": 1.888499648334133e-05,
      "loss": 19.9371,
      "step": 635
    },
    {
      "epoch": 2.0915032679738563,
      "grad_norm": 5.006853103637695,
      "learning_rate": 1.8859659706864234e-05,
      "loss": 19.9602,
      "step": 640
    },
    {
      "epoch": 2.107843137254902,
      "grad_norm": 3.3467419147491455,
      "learning_rate": 1.8834055676742018e-05,
      "loss": 19.9595,
      "step": 645
    },
    {
      "epoch": 2.1241830065359477,
      "grad_norm": 5.145132064819336,
      "learning_rate": 1.880818516532605e-05,
      "loss": 19.8461,
      "step": 650
    },
    {
      "epoch": 2.1241830065359477,
      "eval_loss": 5.132981300354004,
      "eval_runtime": 33.7921,
      "eval_samples_per_second": 4.025,
      "eval_steps_per_second": 0.503,
      "step": 650
    },
    {
      "epoch": 2.1405228758169934,
      "grad_norm": 3.5985190868377686,
      "learning_rate": 1.8782048953006176e-05,
      "loss": 19.8883,
      "step": 655
    },
    {
      "epoch": 2.156862745098039,
      "grad_norm": 4.187699794769287,
      "learning_rate": 1.8755647828187175e-05,
      "loss": 19.8598,
      "step": 660
    },
    {
      "epoch": 2.173202614379085,
      "grad_norm": 2.3095688819885254,
      "learning_rate": 1.8728982587264965e-05,
      "loss": 19.8806,
      "step": 665
    },
    {
      "epoch": 2.189542483660131,
      "grad_norm": 6.535428047180176,
      "learning_rate": 1.870205403460259e-05,
      "loss": 19.9439,
      "step": 670
    },
    {
      "epoch": 2.2058823529411766,
      "grad_norm": 4.472255706787109,
      "learning_rate": 1.8674862982505946e-05,
      "loss": 20.0629,
      "step": 675
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 5.020964622497559,
      "learning_rate": 1.864741025119929e-05,
      "loss": 19.9722,
      "step": 680
    },
    {
      "epoch": 2.238562091503268,
      "grad_norm": 6.127357006072998,
      "learning_rate": 1.8619696668800494e-05,
      "loss": 20.1112,
      "step": 685
    },
    {
      "epoch": 2.2549019607843137,
      "grad_norm": 4.96476411819458,
      "learning_rate": 1.8591723071296054e-05,
      "loss": 19.9425,
      "step": 690
    },
    {
      "epoch": 2.2712418300653594,
      "grad_norm": 5.471144676208496,
      "learning_rate": 1.856349030251589e-05,
      "loss": 19.8543,
      "step": 695
    },
    {
      "epoch": 2.287581699346405,
      "grad_norm": 5.112643718719482,
      "learning_rate": 1.8534999214107878e-05,
      "loss": 19.9281,
      "step": 700
    },
    {
      "epoch": 2.287581699346405,
      "eval_loss": 5.136080265045166,
      "eval_runtime": 33.9985,
      "eval_samples_per_second": 4.0,
      "eval_steps_per_second": 0.5,
      "step": 700
    },
    {
      "epoch": 2.303921568627451,
      "grad_norm": 4.396500587463379,
      "learning_rate": 1.8506250665512156e-05,
      "loss": 19.8284,
      "step": 705
    },
    {
      "epoch": 2.3202614379084965,
      "grad_norm": 5.786165714263916,
      "learning_rate": 1.847724552393522e-05,
      "loss": 19.8532,
      "step": 710
    },
    {
      "epoch": 2.3366013071895426,
      "grad_norm": 4.75067138671875,
      "learning_rate": 1.844798466432375e-05,
      "loss": 19.987,
      "step": 715
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 4.751490116119385,
      "learning_rate": 1.841846896933821e-05,
      "loss": 19.902,
      "step": 720
    },
    {
      "epoch": 2.369281045751634,
      "grad_norm": 4.626798152923584,
      "learning_rate": 1.8388699329326237e-05,
      "loss": 19.8865,
      "step": 725
    },
    {
      "epoch": 2.3856209150326797,
      "grad_norm": 5.702456951141357,
      "learning_rate": 1.8358676642295775e-05,
      "loss": 19.9889,
      "step": 730
    },
    {
      "epoch": 2.4019607843137254,
      "grad_norm": 2.871734142303467,
      "learning_rate": 1.8328401813887994e-05,
      "loss": 19.8896,
      "step": 735
    },
    {
      "epoch": 2.418300653594771,
      "grad_norm": 4.797183036804199,
      "learning_rate": 1.829787575734995e-05,
      "loss": 19.869,
      "step": 740
    },
    {
      "epoch": 2.4346405228758172,
      "grad_norm": 4.487987995147705,
      "learning_rate": 1.8267099393507083e-05,
      "loss": 19.8204,
      "step": 745
    },
    {
      "epoch": 2.450980392156863,
      "grad_norm": 7.268711566925049,
      "learning_rate": 1.823607365073537e-05,
      "loss": 19.9483,
      "step": 750
    },
    {
      "epoch": 2.450980392156863,
      "eval_loss": 5.1463189125061035,
      "eval_runtime": 33.728,
      "eval_samples_per_second": 4.032,
      "eval_steps_per_second": 0.504,
      "step": 750
    },
    {
      "epoch": 2.4673202614379086,
      "grad_norm": 5.690021514892578,
      "learning_rate": 1.82047994649334e-05,
      "loss": 19.8499,
      "step": 755
    },
    {
      "epoch": 2.4836601307189543,
      "grad_norm": 5.747515678405762,
      "learning_rate": 1.817327777949407e-05,
      "loss": 19.8621,
      "step": 760
    },
    {
      "epoch": 2.5,
      "grad_norm": 4.331953525543213,
      "learning_rate": 1.814150954527618e-05,
      "loss": 19.9507,
      "step": 765
    },
    {
      "epoch": 2.5163398692810457,
      "grad_norm": 6.455000877380371,
      "learning_rate": 1.8109495720575715e-05,
      "loss": 19.9937,
      "step": 770
    },
    {
      "epoch": 2.5326797385620914,
      "grad_norm": 5.793630599975586,
      "learning_rate": 1.8077237271096972e-05,
      "loss": 20.041,
      "step": 775
    },
    {
      "epoch": 2.549019607843137,
      "grad_norm": 4.988850116729736,
      "learning_rate": 1.8044735169923387e-05,
      "loss": 19.9383,
      "step": 780
    },
    {
      "epoch": 2.5653594771241828,
      "grad_norm": 3.3700003623962402,
      "learning_rate": 1.801199039748822e-05,
      "loss": 19.837,
      "step": 785
    },
    {
      "epoch": 2.581699346405229,
      "grad_norm": 7.457601547241211,
      "learning_rate": 1.7979003941544965e-05,
      "loss": 19.8527,
      "step": 790
    },
    {
      "epoch": 2.5980392156862746,
      "grad_norm": 5.744372844696045,
      "learning_rate": 1.7945776797137544e-05,
      "loss": 19.8979,
      "step": 795
    },
    {
      "epoch": 2.6143790849673203,
      "grad_norm": 8.07752799987793,
      "learning_rate": 1.791230996657031e-05,
      "loss": 19.9553,
      "step": 800
    },
    {
      "epoch": 2.6143790849673203,
      "eval_loss": 5.142671585083008,
      "eval_runtime": 33.7122,
      "eval_samples_per_second": 4.034,
      "eval_steps_per_second": 0.504,
      "step": 800
    },
    {
      "epoch": 2.630718954248366,
      "grad_norm": 2.3532159328460693,
      "learning_rate": 1.7878604459377795e-05,
      "loss": 19.8843,
      "step": 805
    },
    {
      "epoch": 2.6470588235294117,
      "grad_norm": 4.708276271820068,
      "learning_rate": 1.7844661292294274e-05,
      "loss": 19.9148,
      "step": 810
    },
    {
      "epoch": 2.6633986928104574,
      "grad_norm": 5.070180416107178,
      "learning_rate": 1.7810481489223082e-05,
      "loss": 19.9768,
      "step": 815
    },
    {
      "epoch": 2.6797385620915035,
      "grad_norm": 5.195274353027344,
      "learning_rate": 1.7776066081205738e-05,
      "loss": 19.8998,
      "step": 820
    },
    {
      "epoch": 2.696078431372549,
      "grad_norm": 1.9694629907608032,
      "learning_rate": 1.7741416106390828e-05,
      "loss": 19.8979,
      "step": 825
    },
    {
      "epoch": 2.712418300653595,
      "grad_norm": 4.695465087890625,
      "learning_rate": 1.77065326100027e-05,
      "loss": 19.9916,
      "step": 830
    },
    {
      "epoch": 2.7287581699346406,
      "grad_norm": 3.83286452293396,
      "learning_rate": 1.7671416644309945e-05,
      "loss": 19.6886,
      "step": 835
    },
    {
      "epoch": 2.7450980392156863,
      "grad_norm": 5.557157039642334,
      "learning_rate": 1.7636069268593633e-05,
      "loss": 20.0727,
      "step": 840
    },
    {
      "epoch": 2.761437908496732,
      "grad_norm": 6.84454870223999,
      "learning_rate": 1.760049154911537e-05,
      "loss": 19.8237,
      "step": 845
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 5.825652599334717,
      "learning_rate": 1.7564684559085138e-05,
      "loss": 19.8617,
      "step": 850
    },
    {
      "epoch": 2.7777777777777777,
      "eval_loss": 5.129420280456543,
      "eval_runtime": 33.879,
      "eval_samples_per_second": 4.014,
      "eval_steps_per_second": 0.502,
      "step": 850
    }
  ],
  "logging_steps": 5,
  "max_steps": 3060,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.07313016193024e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
