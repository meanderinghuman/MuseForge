{
  "best_global_step": 850,
  "best_metric": 5.129420280456543,
  "best_model_checkpoint": "./cultural_vlm_working\\checkpoint-850",
  "epoch": 9.967320261437909,
  "eval_steps": 50,
  "global_step": 3050,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.016339869281045753,
      "grad_norm": 38.26896286010742,
      "learning_rate": 4.0000000000000003e-07,
      "loss": 21.5222,
      "step": 5
    },
    {
      "epoch": 0.032679738562091505,
      "grad_norm": 14.553839683532715,
      "learning_rate": 9.000000000000001e-07,
      "loss": 21.5069,
      "step": 10
    },
    {
      "epoch": 0.049019607843137254,
      "grad_norm": 38.59209442138672,
      "learning_rate": 1.4000000000000001e-06,
      "loss": 21.3123,
      "step": 15
    },
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 18.0140380859375,
      "learning_rate": 1.9000000000000002e-06,
      "loss": 21.2238,
      "step": 20
    },
    {
      "epoch": 0.08169934640522876,
      "grad_norm": 15.129743576049805,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 21.207,
      "step": 25
    },
    {
      "epoch": 0.09803921568627451,
      "grad_norm": 55.5308952331543,
      "learning_rate": 2.9e-06,
      "loss": 21.0261,
      "step": 30
    },
    {
      "epoch": 0.11437908496732026,
      "grad_norm": 14.212453842163086,
      "learning_rate": 3.4000000000000005e-06,
      "loss": 21.0572,
      "step": 35
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 59.64015197753906,
      "learning_rate": 3.900000000000001e-06,
      "loss": 20.8219,
      "step": 40
    },
    {
      "epoch": 0.14705882352941177,
      "grad_norm": 65.4885025024414,
      "learning_rate": 4.4e-06,
      "loss": 20.8758,
      "step": 45
    },
    {
      "epoch": 0.16339869281045752,
      "grad_norm": 77.038818359375,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 20.6391,
      "step": 50
    },
    {
      "epoch": 0.16339869281045752,
      "eval_loss": 5.3148956298828125,
      "eval_runtime": 34.4437,
      "eval_samples_per_second": 3.948,
      "eval_steps_per_second": 0.494,
      "step": 50
    },
    {
      "epoch": 0.17973856209150327,
      "grad_norm": 161.172119140625,
      "learning_rate": 5.400000000000001e-06,
      "loss": 20.8137,
      "step": 55
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 92.20557403564453,
      "learning_rate": 5.9e-06,
      "loss": 20.7722,
      "step": 60
    },
    {
      "epoch": 0.21241830065359477,
      "grad_norm": 194.28199768066406,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 20.9152,
      "step": 65
    },
    {
      "epoch": 0.22875816993464052,
      "grad_norm": 12.823917388916016,
      "learning_rate": 6.9e-06,
      "loss": 20.7067,
      "step": 70
    },
    {
      "epoch": 0.24509803921568626,
      "grad_norm": 100.21053314208984,
      "learning_rate": 7.4e-06,
      "loss": 20.7349,
      "step": 75
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 114.09513854980469,
      "learning_rate": 7.9e-06,
      "loss": 20.5388,
      "step": 80
    },
    {
      "epoch": 0.2777777777777778,
      "grad_norm": 80.38729858398438,
      "learning_rate": 8.400000000000001e-06,
      "loss": 20.5389,
      "step": 85
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 15.981563568115234,
      "learning_rate": 8.900000000000001e-06,
      "loss": 20.5069,
      "step": 90
    },
    {
      "epoch": 0.3104575163398693,
      "grad_norm": 41.93463134765625,
      "learning_rate": 9.4e-06,
      "loss": 20.5639,
      "step": 95
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 6.414069652557373,
      "learning_rate": 9.9e-06,
      "loss": 20.5026,
      "step": 100
    },
    {
      "epoch": 0.32679738562091504,
      "eval_loss": 5.256805419921875,
      "eval_runtime": 33.9866,
      "eval_samples_per_second": 4.002,
      "eval_steps_per_second": 0.5,
      "step": 100
    },
    {
      "epoch": 0.3431372549019608,
      "grad_norm": 34.00313949584961,
      "learning_rate": 1.04e-05,
      "loss": 20.521,
      "step": 105
    },
    {
      "epoch": 0.35947712418300654,
      "grad_norm": 8.502431869506836,
      "learning_rate": 1.0900000000000002e-05,
      "loss": 20.6023,
      "step": 110
    },
    {
      "epoch": 0.3758169934640523,
      "grad_norm": 72.1801528930664,
      "learning_rate": 1.14e-05,
      "loss": 20.565,
      "step": 115
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 7.322787284851074,
      "learning_rate": 1.1900000000000001e-05,
      "loss": 20.4804,
      "step": 120
    },
    {
      "epoch": 0.4084967320261438,
      "grad_norm": 77.08651733398438,
      "learning_rate": 1.2400000000000002e-05,
      "loss": 20.404,
      "step": 125
    },
    {
      "epoch": 0.42483660130718953,
      "grad_norm": 114.14712524414062,
      "learning_rate": 1.2900000000000002e-05,
      "loss": 20.5088,
      "step": 130
    },
    {
      "epoch": 0.4411764705882353,
      "grad_norm": 12.71867847442627,
      "learning_rate": 1.3400000000000002e-05,
      "loss": 20.4275,
      "step": 135
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 13.894290924072266,
      "learning_rate": 1.39e-05,
      "loss": 20.481,
      "step": 140
    },
    {
      "epoch": 0.4738562091503268,
      "grad_norm": 97.36418151855469,
      "learning_rate": 1.4400000000000001e-05,
      "loss": 20.4419,
      "step": 145
    },
    {
      "epoch": 0.49019607843137253,
      "grad_norm": 21.132099151611328,
      "learning_rate": 1.4900000000000001e-05,
      "loss": 20.3839,
      "step": 150
    },
    {
      "epoch": 0.49019607843137253,
      "eval_loss": 5.2232666015625,
      "eval_runtime": 33.682,
      "eval_samples_per_second": 4.038,
      "eval_steps_per_second": 0.505,
      "step": 150
    },
    {
      "epoch": 0.5065359477124183,
      "grad_norm": 4.782593250274658,
      "learning_rate": 1.54e-05,
      "loss": 20.3356,
      "step": 155
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 7.651669502258301,
      "learning_rate": 1.5900000000000004e-05,
      "loss": 20.2327,
      "step": 160
    },
    {
      "epoch": 0.5392156862745098,
      "grad_norm": 67.72860717773438,
      "learning_rate": 1.64e-05,
      "loss": 20.2716,
      "step": 165
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 5.029348850250244,
      "learning_rate": 1.69e-05,
      "loss": 20.3602,
      "step": 170
    },
    {
      "epoch": 0.5718954248366013,
      "grad_norm": 6.497302532196045,
      "learning_rate": 1.7400000000000003e-05,
      "loss": 20.4088,
      "step": 175
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 6.576371192932129,
      "learning_rate": 1.79e-05,
      "loss": 20.5499,
      "step": 180
    },
    {
      "epoch": 0.6045751633986928,
      "grad_norm": 13.053315162658691,
      "learning_rate": 1.8400000000000003e-05,
      "loss": 20.1783,
      "step": 185
    },
    {
      "epoch": 0.6209150326797386,
      "grad_norm": 40.93875503540039,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 20.2841,
      "step": 190
    },
    {
      "epoch": 0.6372549019607843,
      "grad_norm": 5.062676906585693,
      "learning_rate": 1.94e-05,
      "loss": 20.2522,
      "step": 195
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 5.72667932510376,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 20.1485,
      "step": 200
    },
    {
      "epoch": 0.6535947712418301,
      "eval_loss": 5.186253070831299,
      "eval_runtime": 33.8114,
      "eval_samples_per_second": 4.022,
      "eval_steps_per_second": 0.503,
      "step": 200
    },
    {
      "epoch": 0.6699346405228758,
      "grad_norm": 8.893180847167969,
      "learning_rate": 1.9999903471186634e-05,
      "loss": 20.2571,
      "step": 205
    },
    {
      "epoch": 0.6862745098039216,
      "grad_norm": 6.275423526763916,
      "learning_rate": 1.9999511326076227e-05,
      "loss": 20.3326,
      "step": 210
    },
    {
      "epoch": 0.7026143790849673,
      "grad_norm": 5.950165271759033,
      "learning_rate": 1.999881754343799e-05,
      "loss": 20.391,
      "step": 215
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 6.285647869110107,
      "learning_rate": 1.9997822144200035e-05,
      "loss": 20.2087,
      "step": 220
    },
    {
      "epoch": 0.7352941176470589,
      "grad_norm": 6.340970516204834,
      "learning_rate": 1.9996525158388804e-05,
      "loss": 20.2168,
      "step": 225
    },
    {
      "epoch": 0.7516339869281046,
      "grad_norm": 5.483854293823242,
      "learning_rate": 1.999492662512817e-05,
      "loss": 20.1133,
      "step": 230
    },
    {
      "epoch": 0.7679738562091504,
      "grad_norm": 4.751608371734619,
      "learning_rate": 1.999302659263825e-05,
      "loss": 20.1599,
      "step": 235
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 4.94934606552124,
      "learning_rate": 1.9990825118233958e-05,
      "loss": 20.1238,
      "step": 240
    },
    {
      "epoch": 0.8006535947712419,
      "grad_norm": 5.156955242156982,
      "learning_rate": 1.998832226832327e-05,
      "loss": 20.2052,
      "step": 245
    },
    {
      "epoch": 0.8169934640522876,
      "grad_norm": 5.369345188140869,
      "learning_rate": 1.998551811840521e-05,
      "loss": 20.2557,
      "step": 250
    },
    {
      "epoch": 0.8169934640522876,
      "eval_loss": 5.167814254760742,
      "eval_runtime": 33.6263,
      "eval_samples_per_second": 4.044,
      "eval_steps_per_second": 0.506,
      "step": 250
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 8.00222396850586,
      "learning_rate": 1.998241275306761e-05,
      "loss": 20.1667,
      "step": 255
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 5.749771595001221,
      "learning_rate": 1.9979006265984516e-05,
      "loss": 20.2071,
      "step": 260
    },
    {
      "epoch": 0.8660130718954249,
      "grad_norm": 9.824156761169434,
      "learning_rate": 1.9975298759913382e-05,
      "loss": 20.0525,
      "step": 265
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 5.066336631774902,
      "learning_rate": 1.997129034669197e-05,
      "loss": 20.1366,
      "step": 270
    },
    {
      "epoch": 0.8986928104575164,
      "grad_norm": 5.567432880401611,
      "learning_rate": 1.9966981147234975e-05,
      "loss": 20.1583,
      "step": 275
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 3.518766403198242,
      "learning_rate": 1.9962371291530375e-05,
      "loss": 20.1634,
      "step": 280
    },
    {
      "epoch": 0.9313725490196079,
      "grad_norm": 6.2730712890625,
      "learning_rate": 1.9957460918635513e-05,
      "loss": 20.1267,
      "step": 285
    },
    {
      "epoch": 0.9477124183006536,
      "grad_norm": 6.248128890991211,
      "learning_rate": 1.9952250176672904e-05,
      "loss": 20.124,
      "step": 290
    },
    {
      "epoch": 0.9640522875816994,
      "grad_norm": 7.347362041473389,
      "learning_rate": 1.994673922282576e-05,
      "loss": 20.0455,
      "step": 295
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 48.801673889160156,
      "learning_rate": 1.9940928223333254e-05,
      "loss": 20.2146,
      "step": 300
    },
    {
      "epoch": 0.9803921568627451,
      "eval_loss": 5.152705669403076,
      "eval_runtime": 33.6908,
      "eval_samples_per_second": 4.037,
      "eval_steps_per_second": 0.505,
      "step": 300
    },
    {
      "epoch": 0.9967320261437909,
      "grad_norm": 5.199045181274414,
      "learning_rate": 1.99348173534855e-05,
      "loss": 20.1672,
      "step": 305
    },
    {
      "epoch": 1.0130718954248366,
      "grad_norm": 4.600134372711182,
      "learning_rate": 1.9928406797618285e-05,
      "loss": 20.135,
      "step": 310
    },
    {
      "epoch": 1.0294117647058822,
      "grad_norm": 5.479318141937256,
      "learning_rate": 1.992169674910747e-05,
      "loss": 20.1584,
      "step": 315
    },
    {
      "epoch": 1.0457516339869282,
      "grad_norm": 6.460124492645264,
      "learning_rate": 1.9914687410363196e-05,
      "loss": 20.0922,
      "step": 320
    },
    {
      "epoch": 1.0620915032679739,
      "grad_norm": 5.794046401977539,
      "learning_rate": 1.9907378992823755e-05,
      "loss": 20.148,
      "step": 325
    },
    {
      "epoch": 1.0784313725490196,
      "grad_norm": 3.8983561992645264,
      "learning_rate": 1.9899771716949218e-05,
      "loss": 20.079,
      "step": 330
    },
    {
      "epoch": 1.0947712418300655,
      "grad_norm": 4.643613338470459,
      "learning_rate": 1.9891865812214793e-05,
      "loss": 19.9603,
      "step": 335
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 5.630549907684326,
      "learning_rate": 1.9883661517103884e-05,
      "loss": 20.0925,
      "step": 340
    },
    {
      "epoch": 1.1274509803921569,
      "grad_norm": 5.30294942855835,
      "learning_rate": 1.9875159079100917e-05,
      "loss": 20.0146,
      "step": 345
    },
    {
      "epoch": 1.1437908496732025,
      "grad_norm": 5.252014636993408,
      "learning_rate": 1.9866358754683864e-05,
      "loss": 20.1395,
      "step": 350
    },
    {
      "epoch": 1.1437908496732025,
      "eval_loss": 5.14545202255249,
      "eval_runtime": 33.6069,
      "eval_samples_per_second": 4.047,
      "eval_steps_per_second": 0.506,
      "step": 350
    },
    {
      "epoch": 1.1601307189542482,
      "grad_norm": 5.0852813720703125,
      "learning_rate": 1.985726080931651e-05,
      "loss": 20.0854,
      "step": 355
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 5.807145595550537,
      "learning_rate": 1.9847865517440438e-05,
      "loss": 20.116,
      "step": 360
    },
    {
      "epoch": 1.1928104575163399,
      "grad_norm": 6.906466960906982,
      "learning_rate": 1.983817316246676e-05,
      "loss": 20.0965,
      "step": 365
    },
    {
      "epoch": 1.2091503267973855,
      "grad_norm": 5.250594615936279,
      "learning_rate": 1.9828184036767556e-05,
      "loss": 20.0758,
      "step": 370
    },
    {
      "epoch": 1.2254901960784315,
      "grad_norm": 4.192443370819092,
      "learning_rate": 1.9817898441667082e-05,
      "loss": 20.05,
      "step": 375
    },
    {
      "epoch": 1.2418300653594772,
      "grad_norm": 5.576468467712402,
      "learning_rate": 1.9807316687432637e-05,
      "loss": 20.005,
      "step": 380
    },
    {
      "epoch": 1.2581699346405228,
      "grad_norm": 4.258819103240967,
      "learning_rate": 1.9796439093265245e-05,
      "loss": 19.936,
      "step": 385
    },
    {
      "epoch": 1.2745098039215685,
      "grad_norm": 4.67460298538208,
      "learning_rate": 1.978526598729e-05,
      "loss": 20.1677,
      "step": 390
    },
    {
      "epoch": 1.2908496732026145,
      "grad_norm": 6.1327691078186035,
      "learning_rate": 1.9773797706546176e-05,
      "loss": 20.0663,
      "step": 395
    },
    {
      "epoch": 1.3071895424836601,
      "grad_norm": 3.7558279037475586,
      "learning_rate": 1.9762034596977066e-05,
      "loss": 19.9031,
      "step": 400
    },
    {
      "epoch": 1.3071895424836601,
      "eval_loss": 5.139065742492676,
      "eval_runtime": 33.6885,
      "eval_samples_per_second": 4.037,
      "eval_steps_per_second": 0.505,
      "step": 400
    },
    {
      "epoch": 1.3235294117647058,
      "grad_norm": 7.098148345947266,
      "learning_rate": 1.9749977013419536e-05,
      "loss": 20.08,
      "step": 405
    },
    {
      "epoch": 1.3398692810457518,
      "grad_norm": 2.3441622257232666,
      "learning_rate": 1.9737625319593338e-05,
      "loss": 20.0416,
      "step": 410
    },
    {
      "epoch": 1.3562091503267975,
      "grad_norm": 7.012580871582031,
      "learning_rate": 1.972497988809011e-05,
      "loss": 20.0398,
      "step": 415
    },
    {
      "epoch": 1.3725490196078431,
      "grad_norm": 5.718914985656738,
      "learning_rate": 1.971204110036216e-05,
      "loss": 20.0089,
      "step": 420
    },
    {
      "epoch": 1.3888888888888888,
      "grad_norm": 6.407711505889893,
      "learning_rate": 1.9698809346710965e-05,
      "loss": 20.0476,
      "step": 425
    },
    {
      "epoch": 1.4052287581699345,
      "grad_norm": 3.751487970352173,
      "learning_rate": 1.968528502627537e-05,
      "loss": 20.0977,
      "step": 430
    },
    {
      "epoch": 1.4215686274509804,
      "grad_norm": 5.3491058349609375,
      "learning_rate": 1.9671468547019575e-05,
      "loss": 20.0833,
      "step": 435
    },
    {
      "epoch": 1.4379084967320261,
      "grad_norm": 5.0723700523376465,
      "learning_rate": 1.96573603257208e-05,
      "loss": 20.0248,
      "step": 440
    },
    {
      "epoch": 1.4542483660130718,
      "grad_norm": 5.068697929382324,
      "learning_rate": 1.964296078795675e-05,
      "loss": 20.0646,
      "step": 445
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 4.390775680541992,
      "learning_rate": 1.962827036809275e-05,
      "loss": 19.9241,
      "step": 450
    },
    {
      "epoch": 1.4705882352941178,
      "eval_loss": 5.14285135269165,
      "eval_runtime": 33.6785,
      "eval_samples_per_second": 4.038,
      "eval_steps_per_second": 0.505,
      "step": 450
    },
    {
      "epoch": 1.4869281045751634,
      "grad_norm": 5.8060784339904785,
      "learning_rate": 1.9613289509268647e-05,
      "loss": 20.002,
      "step": 455
    },
    {
      "epoch": 1.5032679738562091,
      "grad_norm": 5.720840930938721,
      "learning_rate": 1.9598018663385437e-05,
      "loss": 19.9391,
      "step": 460
    },
    {
      "epoch": 1.5196078431372548,
      "grad_norm": 4.700438022613525,
      "learning_rate": 1.9582458291091664e-05,
      "loss": 19.8018,
      "step": 465
    },
    {
      "epoch": 1.5359477124183005,
      "grad_norm": 4.982049465179443,
      "learning_rate": 1.956660886176948e-05,
      "loss": 19.9071,
      "step": 470
    },
    {
      "epoch": 1.5522875816993464,
      "grad_norm": 7.097657680511475,
      "learning_rate": 1.955047085352052e-05,
      "loss": 20.0212,
      "step": 475
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 6.132114410400391,
      "learning_rate": 1.953404475315146e-05,
      "loss": 20.057,
      "step": 480
    },
    {
      "epoch": 1.584967320261438,
      "grad_norm": 6.34305477142334,
      "learning_rate": 1.9517331056159353e-05,
      "loss": 19.9262,
      "step": 485
    },
    {
      "epoch": 1.6013071895424837,
      "grad_norm": 6.554078578948975,
      "learning_rate": 1.950033026671665e-05,
      "loss": 19.9403,
      "step": 490
    },
    {
      "epoch": 1.6176470588235294,
      "grad_norm": 3.5831761360168457,
      "learning_rate": 1.9483042897656032e-05,
      "loss": 19.8551,
      "step": 495
    },
    {
      "epoch": 1.6339869281045751,
      "grad_norm": 5.068871974945068,
      "learning_rate": 1.94654694704549e-05,
      "loss": 19.9741,
      "step": 500
    },
    {
      "epoch": 1.6339869281045751,
      "eval_loss": 5.142055511474609,
      "eval_runtime": 33.6925,
      "eval_samples_per_second": 4.037,
      "eval_steps_per_second": 0.505,
      "step": 500
    },
    {
      "epoch": 1.6503267973856208,
      "grad_norm": 6.045853614807129,
      "learning_rate": 1.944761051521968e-05,
      "loss": 19.9321,
      "step": 505
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 4.967005729675293,
      "learning_rate": 1.94294665706698e-05,
      "loss": 20.0652,
      "step": 510
    },
    {
      "epoch": 1.6830065359477124,
      "grad_norm": 4.294905185699463,
      "learning_rate": 1.941103818412147e-05,
      "loss": 19.9015,
      "step": 515
    },
    {
      "epoch": 1.6993464052287581,
      "grad_norm": 5.494741439819336,
      "learning_rate": 1.9392325911471154e-05,
      "loss": 20.0609,
      "step": 520
    },
    {
      "epoch": 1.715686274509804,
      "grad_norm": 6.369626045227051,
      "learning_rate": 1.9373330317178797e-05,
      "loss": 20.126,
      "step": 525
    },
    {
      "epoch": 1.7320261437908497,
      "grad_norm": 6.590451717376709,
      "learning_rate": 1.935405197425081e-05,
      "loss": 19.9955,
      "step": 530
    },
    {
      "epoch": 1.7483660130718954,
      "grad_norm": 5.64064884185791,
      "learning_rate": 1.933449146422278e-05,
      "loss": 20.0338,
      "step": 535
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 5.716353893280029,
      "learning_rate": 1.9314649377141935e-05,
      "loss": 20.0079,
      "step": 540
    },
    {
      "epoch": 1.7810457516339868,
      "grad_norm": 6.537838459014893,
      "learning_rate": 1.929452631154933e-05,
      "loss": 19.9883,
      "step": 545
    },
    {
      "epoch": 1.7973856209150327,
      "grad_norm": 6.780081272125244,
      "learning_rate": 1.9274122874461808e-05,
      "loss": 19.8853,
      "step": 550
    },
    {
      "epoch": 1.7973856209150327,
      "eval_loss": 5.133040428161621,
      "eval_runtime": 33.6863,
      "eval_samples_per_second": 4.037,
      "eval_steps_per_second": 0.505,
      "step": 550
    },
    {
      "epoch": 1.8137254901960784,
      "grad_norm": 7.432119846343994,
      "learning_rate": 1.9253439681353673e-05,
      "loss": 20.1302,
      "step": 555
    },
    {
      "epoch": 1.8300653594771243,
      "grad_norm": 4.031381130218506,
      "learning_rate": 1.923247735613814e-05,
      "loss": 20.05,
      "step": 560
    },
    {
      "epoch": 1.84640522875817,
      "grad_norm": 5.203853130340576,
      "learning_rate": 1.92112365311485e-05,
      "loss": 20.0474,
      "step": 565
    },
    {
      "epoch": 1.8627450980392157,
      "grad_norm": 3.734973907470703,
      "learning_rate": 1.918971784711907e-05,
      "loss": 19.897,
      "step": 570
    },
    {
      "epoch": 1.8790849673202614,
      "grad_norm": 5.472614288330078,
      "learning_rate": 1.9167921953165827e-05,
      "loss": 20.0045,
      "step": 575
    },
    {
      "epoch": 1.8954248366013071,
      "grad_norm": 5.719069480895996,
      "learning_rate": 1.9145849506766856e-05,
      "loss": 19.9398,
      "step": 580
    },
    {
      "epoch": 1.9117647058823528,
      "grad_norm": 4.3435750007629395,
      "learning_rate": 1.9123501173742514e-05,
      "loss": 19.9527,
      "step": 585
    },
    {
      "epoch": 1.9281045751633987,
      "grad_norm": 5.0592498779296875,
      "learning_rate": 1.9100877628235337e-05,
      "loss": 20.011,
      "step": 590
    },
    {
      "epoch": 1.9444444444444444,
      "grad_norm": 5.334160327911377,
      "learning_rate": 1.9077979552689708e-05,
      "loss": 19.9951,
      "step": 595
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 5.9663872718811035,
      "learning_rate": 1.9054807637831268e-05,
      "loss": 20.0482,
      "step": 600
    },
    {
      "epoch": 1.9607843137254903,
      "eval_loss": 5.1385321617126465,
      "eval_runtime": 33.6224,
      "eval_samples_per_second": 4.045,
      "eval_steps_per_second": 0.506,
      "step": 600
    },
    {
      "epoch": 1.977124183006536,
      "grad_norm": 4.633193016052246,
      "learning_rate": 1.903136258264609e-05,
      "loss": 19.9521,
      "step": 605
    },
    {
      "epoch": 1.9934640522875817,
      "grad_norm": 5.208354473114014,
      "learning_rate": 1.9007645094359576e-05,
      "loss": 19.969,
      "step": 610
    },
    {
      "epoch": 2.0098039215686274,
      "grad_norm": 4.677134037017822,
      "learning_rate": 1.898365588841515e-05,
      "loss": 19.9351,
      "step": 615
    },
    {
      "epoch": 2.026143790849673,
      "grad_norm": 6.793292999267578,
      "learning_rate": 1.8959395688452648e-05,
      "loss": 20.0349,
      "step": 620
    },
    {
      "epoch": 2.042483660130719,
      "grad_norm": 4.798228740692139,
      "learning_rate": 1.8934865226286507e-05,
      "loss": 20.0649,
      "step": 625
    },
    {
      "epoch": 2.0588235294117645,
      "grad_norm": 4.840968608856201,
      "learning_rate": 1.891006524188368e-05,
      "loss": 19.9547,
      "step": 630
    },
    {
      "epoch": 2.0751633986928106,
      "grad_norm": 4.045525550842285,
      "learning_rate": 1.888499648334133e-05,
      "loss": 19.9371,
      "step": 635
    },
    {
      "epoch": 2.0915032679738563,
      "grad_norm": 5.006853103637695,
      "learning_rate": 1.8859659706864234e-05,
      "loss": 19.9602,
      "step": 640
    },
    {
      "epoch": 2.107843137254902,
      "grad_norm": 3.3467419147491455,
      "learning_rate": 1.8834055676742018e-05,
      "loss": 19.9595,
      "step": 645
    },
    {
      "epoch": 2.1241830065359477,
      "grad_norm": 5.145132064819336,
      "learning_rate": 1.880818516532605e-05,
      "loss": 19.8461,
      "step": 650
    },
    {
      "epoch": 2.1241830065359477,
      "eval_loss": 5.132981300354004,
      "eval_runtime": 33.7921,
      "eval_samples_per_second": 4.025,
      "eval_steps_per_second": 0.503,
      "step": 650
    },
    {
      "epoch": 2.1405228758169934,
      "grad_norm": 3.5985190868377686,
      "learning_rate": 1.8782048953006176e-05,
      "loss": 19.8883,
      "step": 655
    },
    {
      "epoch": 2.156862745098039,
      "grad_norm": 4.187699794769287,
      "learning_rate": 1.8755647828187175e-05,
      "loss": 19.8598,
      "step": 660
    },
    {
      "epoch": 2.173202614379085,
      "grad_norm": 2.3095688819885254,
      "learning_rate": 1.8728982587264965e-05,
      "loss": 19.8806,
      "step": 665
    },
    {
      "epoch": 2.189542483660131,
      "grad_norm": 6.535428047180176,
      "learning_rate": 1.870205403460259e-05,
      "loss": 19.9439,
      "step": 670
    },
    {
      "epoch": 2.2058823529411766,
      "grad_norm": 4.472255706787109,
      "learning_rate": 1.8674862982505946e-05,
      "loss": 20.0629,
      "step": 675
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 5.020964622497559,
      "learning_rate": 1.864741025119929e-05,
      "loss": 19.9722,
      "step": 680
    },
    {
      "epoch": 2.238562091503268,
      "grad_norm": 6.127357006072998,
      "learning_rate": 1.8619696668800494e-05,
      "loss": 20.1112,
      "step": 685
    },
    {
      "epoch": 2.2549019607843137,
      "grad_norm": 4.96476411819458,
      "learning_rate": 1.8591723071296054e-05,
      "loss": 19.9425,
      "step": 690
    },
    {
      "epoch": 2.2712418300653594,
      "grad_norm": 5.471144676208496,
      "learning_rate": 1.856349030251589e-05,
      "loss": 19.8543,
      "step": 695
    },
    {
      "epoch": 2.287581699346405,
      "grad_norm": 5.112643718719482,
      "learning_rate": 1.8534999214107878e-05,
      "loss": 19.9281,
      "step": 700
    },
    {
      "epoch": 2.287581699346405,
      "eval_loss": 5.136080265045166,
      "eval_runtime": 33.9985,
      "eval_samples_per_second": 4.0,
      "eval_steps_per_second": 0.5,
      "step": 700
    },
    {
      "epoch": 2.303921568627451,
      "grad_norm": 4.396500587463379,
      "learning_rate": 1.8506250665512156e-05,
      "loss": 19.8284,
      "step": 705
    },
    {
      "epoch": 2.3202614379084965,
      "grad_norm": 5.786165714263916,
      "learning_rate": 1.847724552393522e-05,
      "loss": 19.8532,
      "step": 710
    },
    {
      "epoch": 2.3366013071895426,
      "grad_norm": 4.75067138671875,
      "learning_rate": 1.844798466432375e-05,
      "loss": 19.987,
      "step": 715
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 4.751490116119385,
      "learning_rate": 1.841846896933821e-05,
      "loss": 19.902,
      "step": 720
    },
    {
      "epoch": 2.369281045751634,
      "grad_norm": 4.626798152923584,
      "learning_rate": 1.8388699329326237e-05,
      "loss": 19.8865,
      "step": 725
    },
    {
      "epoch": 2.3856209150326797,
      "grad_norm": 5.702456951141357,
      "learning_rate": 1.8358676642295775e-05,
      "loss": 19.9889,
      "step": 730
    },
    {
      "epoch": 2.4019607843137254,
      "grad_norm": 2.871734142303467,
      "learning_rate": 1.8328401813887994e-05,
      "loss": 19.8896,
      "step": 735
    },
    {
      "epoch": 2.418300653594771,
      "grad_norm": 4.797183036804199,
      "learning_rate": 1.829787575734995e-05,
      "loss": 19.869,
      "step": 740
    },
    {
      "epoch": 2.4346405228758172,
      "grad_norm": 4.487987995147705,
      "learning_rate": 1.8267099393507083e-05,
      "loss": 19.8204,
      "step": 745
    },
    {
      "epoch": 2.450980392156863,
      "grad_norm": 7.268711566925049,
      "learning_rate": 1.823607365073537e-05,
      "loss": 19.9483,
      "step": 750
    },
    {
      "epoch": 2.450980392156863,
      "eval_loss": 5.1463189125061035,
      "eval_runtime": 33.728,
      "eval_samples_per_second": 4.032,
      "eval_steps_per_second": 0.504,
      "step": 750
    },
    {
      "epoch": 2.4673202614379086,
      "grad_norm": 5.690021514892578,
      "learning_rate": 1.82047994649334e-05,
      "loss": 19.8499,
      "step": 755
    },
    {
      "epoch": 2.4836601307189543,
      "grad_norm": 5.747515678405762,
      "learning_rate": 1.817327777949407e-05,
      "loss": 19.8621,
      "step": 760
    },
    {
      "epoch": 2.5,
      "grad_norm": 4.331953525543213,
      "learning_rate": 1.814150954527618e-05,
      "loss": 19.9507,
      "step": 765
    },
    {
      "epoch": 2.5163398692810457,
      "grad_norm": 6.455000877380371,
      "learning_rate": 1.8109495720575715e-05,
      "loss": 19.9937,
      "step": 770
    },
    {
      "epoch": 2.5326797385620914,
      "grad_norm": 5.793630599975586,
      "learning_rate": 1.8077237271096972e-05,
      "loss": 20.041,
      "step": 775
    },
    {
      "epoch": 2.549019607843137,
      "grad_norm": 4.988850116729736,
      "learning_rate": 1.8044735169923387e-05,
      "loss": 19.9383,
      "step": 780
    },
    {
      "epoch": 2.5653594771241828,
      "grad_norm": 3.3700003623962402,
      "learning_rate": 1.801199039748822e-05,
      "loss": 19.837,
      "step": 785
    },
    {
      "epoch": 2.581699346405229,
      "grad_norm": 7.457601547241211,
      "learning_rate": 1.7979003941544965e-05,
      "loss": 19.8527,
      "step": 790
    },
    {
      "epoch": 2.5980392156862746,
      "grad_norm": 5.744372844696045,
      "learning_rate": 1.7945776797137544e-05,
      "loss": 19.8979,
      "step": 795
    },
    {
      "epoch": 2.6143790849673203,
      "grad_norm": 8.07752799987793,
      "learning_rate": 1.791230996657031e-05,
      "loss": 19.9553,
      "step": 800
    },
    {
      "epoch": 2.6143790849673203,
      "eval_loss": 5.142671585083008,
      "eval_runtime": 33.7122,
      "eval_samples_per_second": 4.034,
      "eval_steps_per_second": 0.504,
      "step": 800
    },
    {
      "epoch": 2.630718954248366,
      "grad_norm": 2.3532159328460693,
      "learning_rate": 1.7878604459377795e-05,
      "loss": 19.8843,
      "step": 805
    },
    {
      "epoch": 2.6470588235294117,
      "grad_norm": 4.708276271820068,
      "learning_rate": 1.7844661292294274e-05,
      "loss": 19.9148,
      "step": 810
    },
    {
      "epoch": 2.6633986928104574,
      "grad_norm": 5.070180416107178,
      "learning_rate": 1.7810481489223082e-05,
      "loss": 19.9768,
      "step": 815
    },
    {
      "epoch": 2.6797385620915035,
      "grad_norm": 5.195274353027344,
      "learning_rate": 1.7776066081205738e-05,
      "loss": 19.8998,
      "step": 820
    },
    {
      "epoch": 2.696078431372549,
      "grad_norm": 1.9694629907608032,
      "learning_rate": 1.7741416106390828e-05,
      "loss": 19.8979,
      "step": 825
    },
    {
      "epoch": 2.712418300653595,
      "grad_norm": 4.695465087890625,
      "learning_rate": 1.77065326100027e-05,
      "loss": 19.9916,
      "step": 830
    },
    {
      "epoch": 2.7287581699346406,
      "grad_norm": 3.83286452293396,
      "learning_rate": 1.7671416644309945e-05,
      "loss": 19.6886,
      "step": 835
    },
    {
      "epoch": 2.7450980392156863,
      "grad_norm": 5.557157039642334,
      "learning_rate": 1.7636069268593633e-05,
      "loss": 20.0727,
      "step": 840
    },
    {
      "epoch": 2.761437908496732,
      "grad_norm": 6.84454870223999,
      "learning_rate": 1.760049154911537e-05,
      "loss": 19.8237,
      "step": 845
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 5.825652599334717,
      "learning_rate": 1.7564684559085138e-05,
      "loss": 19.8617,
      "step": 850
    },
    {
      "epoch": 2.7777777777777777,
      "eval_loss": 5.129420280456543,
      "eval_runtime": 33.879,
      "eval_samples_per_second": 4.014,
      "eval_steps_per_second": 0.502,
      "step": 850
    },
    {
      "epoch": 2.7941176470588234,
      "grad_norm": 4.930052757263184,
      "learning_rate": 1.7528649378628912e-05,
      "loss": 19.7952,
      "step": 855
    },
    {
      "epoch": 2.810457516339869,
      "grad_norm": 4.637636184692383,
      "learning_rate": 1.7492387094756088e-05,
      "loss": 20.0567,
      "step": 860
    },
    {
      "epoch": 2.8267973856209148,
      "grad_norm": 5.974454402923584,
      "learning_rate": 1.7455898801326685e-05,
      "loss": 19.9647,
      "step": 865
    },
    {
      "epoch": 2.843137254901961,
      "grad_norm": 4.972156047821045,
      "learning_rate": 1.7419185599018356e-05,
      "loss": 19.9685,
      "step": 870
    },
    {
      "epoch": 2.8594771241830066,
      "grad_norm": 7.136143207550049,
      "learning_rate": 1.7382248595293175e-05,
      "loss": 19.8237,
      "step": 875
    },
    {
      "epoch": 2.8758169934640523,
      "grad_norm": 6.809573650360107,
      "learning_rate": 1.734508890436424e-05,
      "loss": 19.9754,
      "step": 880
    },
    {
      "epoch": 2.892156862745098,
      "grad_norm": 5.495063781738281,
      "learning_rate": 1.730770764716206e-05,
      "loss": 19.9242,
      "step": 885
    },
    {
      "epoch": 2.9084967320261437,
      "grad_norm": 5.806372165679932,
      "learning_rate": 1.727010595130074e-05,
      "loss": 19.9926,
      "step": 890
    },
    {
      "epoch": 2.92483660130719,
      "grad_norm": 5.573022365570068,
      "learning_rate": 1.7232284951043962e-05,
      "loss": 19.8817,
      "step": 895
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 7.147769927978516,
      "learning_rate": 1.7194245787270784e-05,
      "loss": 20.0593,
      "step": 900
    },
    {
      "epoch": 2.9411764705882355,
      "eval_loss": 5.139736652374268,
      "eval_runtime": 33.8842,
      "eval_samples_per_second": 4.014,
      "eval_steps_per_second": 0.502,
      "step": 900
    },
    {
      "epoch": 2.957516339869281,
      "grad_norm": 4.983059406280518,
      "learning_rate": 1.715598960744121e-05,
      "loss": 19.8777,
      "step": 905
    },
    {
      "epoch": 2.973856209150327,
      "grad_norm": 3.2913613319396973,
      "learning_rate": 1.7117517565561588e-05,
      "loss": 20.054,
      "step": 910
    },
    {
      "epoch": 2.9901960784313726,
      "grad_norm": 3.7554991245269775,
      "learning_rate": 1.7078830822149784e-05,
      "loss": 19.9993,
      "step": 915
    },
    {
      "epoch": 3.0065359477124183,
      "grad_norm": 2.5573618412017822,
      "learning_rate": 1.7039930544200194e-05,
      "loss": 19.9405,
      "step": 920
    },
    {
      "epoch": 3.022875816993464,
      "grad_norm": 4.745835781097412,
      "learning_rate": 1.7000817905148523e-05,
      "loss": 19.8168,
      "step": 925
    },
    {
      "epoch": 3.0392156862745097,
      "grad_norm": 4.277796745300293,
      "learning_rate": 1.6961494084836405e-05,
      "loss": 19.8566,
      "step": 930
    },
    {
      "epoch": 3.0555555555555554,
      "grad_norm": 1.6048994064331055,
      "learning_rate": 1.6921960269475806e-05,
      "loss": 19.8415,
      "step": 935
    },
    {
      "epoch": 3.0718954248366015,
      "grad_norm": 4.504369735717773,
      "learning_rate": 1.688221765161323e-05,
      "loss": 19.9121,
      "step": 940
    },
    {
      "epoch": 3.088235294117647,
      "grad_norm": 6.169183254241943,
      "learning_rate": 1.6842267430093762e-05,
      "loss": 19.9795,
      "step": 945
    },
    {
      "epoch": 3.104575163398693,
      "grad_norm": 4.8943681716918945,
      "learning_rate": 1.68021108100249e-05,
      "loss": 19.9163,
      "step": 950
    },
    {
      "epoch": 3.104575163398693,
      "eval_loss": 5.144842624664307,
      "eval_runtime": 33.6612,
      "eval_samples_per_second": 4.04,
      "eval_steps_per_second": 0.505,
      "step": 950
    },
    {
      "epoch": 3.1209150326797386,
      "grad_norm": 7.058422088623047,
      "learning_rate": 1.6761749002740195e-05,
      "loss": 19.9502,
      "step": 955
    },
    {
      "epoch": 3.1372549019607843,
      "grad_norm": 2.5269126892089844,
      "learning_rate": 1.6721183225762726e-05,
      "loss": 19.9235,
      "step": 960
    },
    {
      "epoch": 3.15359477124183,
      "grad_norm": 5.467147350311279,
      "learning_rate": 1.6680414702768358e-05,
      "loss": 19.8933,
      "step": 965
    },
    {
      "epoch": 3.1699346405228757,
      "grad_norm": 5.266443252563477,
      "learning_rate": 1.663944466354884e-05,
      "loss": 19.8749,
      "step": 970
    },
    {
      "epoch": 3.186274509803922,
      "grad_norm": 5.32767915725708,
      "learning_rate": 1.6598274343974688e-05,
      "loss": 19.8597,
      "step": 975
    },
    {
      "epoch": 3.2026143790849675,
      "grad_norm": 5.239255428314209,
      "learning_rate": 1.6556904985957946e-05,
      "loss": 19.8555,
      "step": 980
    },
    {
      "epoch": 3.218954248366013,
      "grad_norm": 7.1078948974609375,
      "learning_rate": 1.6515337837414677e-05,
      "loss": 19.7135,
      "step": 985
    },
    {
      "epoch": 3.235294117647059,
      "grad_norm": 3.781813859939575,
      "learning_rate": 1.647357415222735e-05,
      "loss": 19.8924,
      "step": 990
    },
    {
      "epoch": 3.2516339869281046,
      "grad_norm": 4.168006420135498,
      "learning_rate": 1.6431615190207003e-05,
      "loss": 19.9506,
      "step": 995
    },
    {
      "epoch": 3.2679738562091503,
      "grad_norm": 1.3189760446548462,
      "learning_rate": 1.638946221705525e-05,
      "loss": 19.8665,
      "step": 1000
    },
    {
      "epoch": 3.2679738562091503,
      "eval_loss": 5.142964839935303,
      "eval_runtime": 33.7583,
      "eval_samples_per_second": 4.029,
      "eval_steps_per_second": 0.504,
      "step": 1000
    },
    {
      "epoch": 3.284313725490196,
      "grad_norm": 5.151920795440674,
      "learning_rate": 1.6347116504326082e-05,
      "loss": 19.9044,
      "step": 1005
    },
    {
      "epoch": 3.3006535947712417,
      "grad_norm": 3.998159646987915,
      "learning_rate": 1.6304579329387534e-05,
      "loss": 19.8942,
      "step": 1010
    },
    {
      "epoch": 3.3169934640522873,
      "grad_norm": 4.854533672332764,
      "learning_rate": 1.626185197538314e-05,
      "loss": 19.8328,
      "step": 1015
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 4.148899555206299,
      "learning_rate": 1.6218935731193223e-05,
      "loss": 19.8817,
      "step": 1020
    },
    {
      "epoch": 3.349673202614379,
      "grad_norm": 4.77041482925415,
      "learning_rate": 1.6175831891396034e-05,
      "loss": 19.9008,
      "step": 1025
    },
    {
      "epoch": 3.366013071895425,
      "grad_norm": 3.466475009918213,
      "learning_rate": 1.613254175622867e-05,
      "loss": 19.9205,
      "step": 1030
    },
    {
      "epoch": 3.3823529411764706,
      "grad_norm": 5.365445137023926,
      "learning_rate": 1.6089066631547893e-05,
      "loss": 19.9771,
      "step": 1035
    },
    {
      "epoch": 3.3986928104575163,
      "grad_norm": 8.078125,
      "learning_rate": 1.6045407828790686e-05,
      "loss": 19.8007,
      "step": 1040
    },
    {
      "epoch": 3.415032679738562,
      "grad_norm": 6.433842658996582,
      "learning_rate": 1.600156666493475e-05,
      "loss": 19.8569,
      "step": 1045
    },
    {
      "epoch": 3.431372549019608,
      "grad_norm": 5.787981033325195,
      "learning_rate": 1.595754446245874e-05,
      "loss": 19.8372,
      "step": 1050
    },
    {
      "epoch": 3.431372549019608,
      "eval_loss": 5.140249729156494,
      "eval_runtime": 33.857,
      "eval_samples_per_second": 4.017,
      "eval_steps_per_second": 0.502,
      "step": 1050
    },
    {
      "epoch": 3.447712418300654,
      "grad_norm": 6.2263288497924805,
      "learning_rate": 1.5913342549302378e-05,
      "loss": 19.8084,
      "step": 1055
    },
    {
      "epoch": 3.4640522875816995,
      "grad_norm": 3.1698153018951416,
      "learning_rate": 1.5868962258826407e-05,
      "loss": 19.8152,
      "step": 1060
    },
    {
      "epoch": 3.480392156862745,
      "grad_norm": 6.416422367095947,
      "learning_rate": 1.5824404929772347e-05,
      "loss": 19.8862,
      "step": 1065
    },
    {
      "epoch": 3.496732026143791,
      "grad_norm": 6.833303451538086,
      "learning_rate": 1.577967190622215e-05,
      "loss": 19.8966,
      "step": 1070
    },
    {
      "epoch": 3.5130718954248366,
      "grad_norm": 3.8524434566497803,
      "learning_rate": 1.5734764537557617e-05,
      "loss": 19.8895,
      "step": 1075
    },
    {
      "epoch": 3.5294117647058822,
      "grad_norm": 3.5345335006713867,
      "learning_rate": 1.568968417841971e-05,
      "loss": 19.8508,
      "step": 1080
    },
    {
      "epoch": 3.545751633986928,
      "grad_norm": 3.893129348754883,
      "learning_rate": 1.5644432188667695e-05,
      "loss": 19.9843,
      "step": 1085
    },
    {
      "epoch": 3.5620915032679736,
      "grad_norm": 2.3424956798553467,
      "learning_rate": 1.5599009933338102e-05,
      "loss": 19.8433,
      "step": 1090
    },
    {
      "epoch": 3.5784313725490198,
      "grad_norm": 4.578014850616455,
      "learning_rate": 1.5553418782603574e-05,
      "loss": 19.8351,
      "step": 1095
    },
    {
      "epoch": 3.5947712418300655,
      "grad_norm": 6.26997184753418,
      "learning_rate": 1.5507660111731514e-05,
      "loss": 19.8482,
      "step": 1100
    },
    {
      "epoch": 3.5947712418300655,
      "eval_loss": 5.154348850250244,
      "eval_runtime": 33.8086,
      "eval_samples_per_second": 4.023,
      "eval_steps_per_second": 0.503,
      "step": 1100
    },
    {
      "epoch": 3.611111111111111,
      "grad_norm": 6.013632774353027,
      "learning_rate": 1.5461735301042615e-05,
      "loss": 19.8654,
      "step": 1105
    },
    {
      "epoch": 3.627450980392157,
      "grad_norm": 6.403062343597412,
      "learning_rate": 1.5415645735869206e-05,
      "loss": 19.8722,
      "step": 1110
    },
    {
      "epoch": 3.6437908496732025,
      "grad_norm": 2.8074119091033936,
      "learning_rate": 1.536939280651348e-05,
      "loss": 19.9094,
      "step": 1115
    },
    {
      "epoch": 3.6601307189542482,
      "grad_norm": 3.341318130493164,
      "learning_rate": 1.5322977908205537e-05,
      "loss": 19.8587,
      "step": 1120
    },
    {
      "epoch": 3.6764705882352944,
      "grad_norm": 5.003391265869141,
      "learning_rate": 1.527640244106133e-05,
      "loss": 19.9343,
      "step": 1125
    },
    {
      "epoch": 3.69281045751634,
      "grad_norm": 8.597511291503906,
      "learning_rate": 1.522966781004038e-05,
      "loss": 19.8638,
      "step": 1130
    },
    {
      "epoch": 3.7091503267973858,
      "grad_norm": 6.661762714385986,
      "learning_rate": 1.5182775424903437e-05,
      "loss": 20.0024,
      "step": 1135
    },
    {
      "epoch": 3.7254901960784315,
      "grad_norm": 5.204155445098877,
      "learning_rate": 1.5135726700169944e-05,
      "loss": 19.9776,
      "step": 1140
    },
    {
      "epoch": 3.741830065359477,
      "grad_norm": 3.8178470134735107,
      "learning_rate": 1.508852305507535e-05,
      "loss": 19.8657,
      "step": 1145
    },
    {
      "epoch": 3.758169934640523,
      "grad_norm": 4.310662746429443,
      "learning_rate": 1.504116591352832e-05,
      "loss": 19.8396,
      "step": 1150
    },
    {
      "epoch": 3.758169934640523,
      "eval_loss": 5.142157077789307,
      "eval_runtime": 33.792,
      "eval_samples_per_second": 4.025,
      "eval_steps_per_second": 0.503,
      "step": 1150
    },
    {
      "epoch": 3.7745098039215685,
      "grad_norm": 4.585601329803467,
      "learning_rate": 1.4993656704067777e-05,
      "loss": 19.8427,
      "step": 1155
    },
    {
      "epoch": 3.7908496732026142,
      "grad_norm": 7.255974292755127,
      "learning_rate": 1.4945996859819799e-05,
      "loss": 19.8536,
      "step": 1160
    },
    {
      "epoch": 3.80718954248366,
      "grad_norm": 4.591383457183838,
      "learning_rate": 1.4898187818454401e-05,
      "loss": 19.7997,
      "step": 1165
    },
    {
      "epoch": 3.8235294117647056,
      "grad_norm": 4.360942363739014,
      "learning_rate": 1.4850231022142163e-05,
      "loss": 19.9485,
      "step": 1170
    },
    {
      "epoch": 3.8398692810457518,
      "grad_norm": 8.278654098510742,
      "learning_rate": 1.4802127917510731e-05,
      "loss": 19.8054,
      "step": 1175
    },
    {
      "epoch": 3.8562091503267975,
      "grad_norm": 4.0503692626953125,
      "learning_rate": 1.4753879955601162e-05,
      "loss": 19.6844,
      "step": 1180
    },
    {
      "epoch": 3.872549019607843,
      "grad_norm": 2.8663277626037598,
      "learning_rate": 1.4705488591824182e-05,
      "loss": 19.7873,
      "step": 1185
    },
    {
      "epoch": 3.888888888888889,
      "grad_norm": 4.256977558135986,
      "learning_rate": 1.465695528591625e-05,
      "loss": 19.8678,
      "step": 1190
    },
    {
      "epoch": 3.9052287581699345,
      "grad_norm": 5.020533561706543,
      "learning_rate": 1.4608281501895551e-05,
      "loss": 19.8918,
      "step": 1195
    },
    {
      "epoch": 3.9215686274509802,
      "grad_norm": 6.054771900177002,
      "learning_rate": 1.455946870801783e-05,
      "loss": 19.8938,
      "step": 1200
    },
    {
      "epoch": 3.9215686274509802,
      "eval_loss": 5.140142917633057,
      "eval_runtime": 33.789,
      "eval_samples_per_second": 4.025,
      "eval_steps_per_second": 0.503,
      "step": 1200
    },
    {
      "epoch": 3.9379084967320264,
      "grad_norm": 2.5668702125549316,
      "learning_rate": 1.4510518376732081e-05,
      "loss": 19.7489,
      "step": 1205
    },
    {
      "epoch": 3.954248366013072,
      "grad_norm": 4.382267475128174,
      "learning_rate": 1.4461431984636158e-05,
      "loss": 19.7903,
      "step": 1210
    },
    {
      "epoch": 3.9705882352941178,
      "grad_norm": 6.635207653045654,
      "learning_rate": 1.4412211012432213e-05,
      "loss": 19.8613,
      "step": 1215
    },
    {
      "epoch": 3.9869281045751634,
      "grad_norm": 4.981899738311768,
      "learning_rate": 1.4362856944882041e-05,
      "loss": 19.9306,
      "step": 1220
    },
    {
      "epoch": 4.003267973856209,
      "grad_norm": 2.6844186782836914,
      "learning_rate": 1.431337127076229e-05,
      "loss": 19.8049,
      "step": 1225
    },
    {
      "epoch": 4.019607843137255,
      "grad_norm": 3.81622314453125,
      "learning_rate": 1.426375548281954e-05,
      "loss": 19.8919,
      "step": 1230
    },
    {
      "epoch": 4.0359477124183005,
      "grad_norm": 2.3753323554992676,
      "learning_rate": 1.4214011077725293e-05,
      "loss": 19.7533,
      "step": 1235
    },
    {
      "epoch": 4.052287581699346,
      "grad_norm": 5.1981024742126465,
      "learning_rate": 1.4164139556030818e-05,
      "loss": 19.7877,
      "step": 1240
    },
    {
      "epoch": 4.068627450980392,
      "grad_norm": 5.181621551513672,
      "learning_rate": 1.4114142422121879e-05,
      "loss": 19.7979,
      "step": 1245
    },
    {
      "epoch": 4.084967320261438,
      "grad_norm": 4.192704200744629,
      "learning_rate": 1.4064021184173364e-05,
      "loss": 19.9338,
      "step": 1250
    },
    {
      "epoch": 4.084967320261438,
      "eval_loss": 5.147867679595947,
      "eval_runtime": 33.8214,
      "eval_samples_per_second": 4.021,
      "eval_steps_per_second": 0.503,
      "step": 1250
    },
    {
      "epoch": 4.101307189542483,
      "grad_norm": 6.992084980010986,
      "learning_rate": 1.401377735410379e-05,
      "loss": 20.002,
      "step": 1255
    },
    {
      "epoch": 4.117647058823529,
      "grad_norm": 4.456813812255859,
      "learning_rate": 1.3963412447529687e-05,
      "loss": 19.9153,
      "step": 1260
    },
    {
      "epoch": 4.133986928104576,
      "grad_norm": 2.1857054233551025,
      "learning_rate": 1.3912927983719888e-05,
      "loss": 19.9036,
      "step": 1265
    },
    {
      "epoch": 4.150326797385621,
      "grad_norm": 5.601729869842529,
      "learning_rate": 1.3862325485549702e-05,
      "loss": 19.8874,
      "step": 1270
    },
    {
      "epoch": 4.166666666666667,
      "grad_norm": 3.56300950050354,
      "learning_rate": 1.3811606479454961e-05,
      "loss": 19.7831,
      "step": 1275
    },
    {
      "epoch": 4.183006535947713,
      "grad_norm": 4.721493244171143,
      "learning_rate": 1.3760772495385998e-05,
      "loss": 19.8059,
      "step": 1280
    },
    {
      "epoch": 4.199346405228758,
      "grad_norm": 4.473579406738281,
      "learning_rate": 1.370982506676147e-05,
      "loss": 19.9584,
      "step": 1285
    },
    {
      "epoch": 4.215686274509804,
      "grad_norm": 4.023486614227295,
      "learning_rate": 1.3658765730422126e-05,
      "loss": 19.7876,
      "step": 1290
    },
    {
      "epoch": 4.23202614379085,
      "grad_norm": 2.5946998596191406,
      "learning_rate": 1.3607596026584423e-05,
      "loss": 19.8457,
      "step": 1295
    },
    {
      "epoch": 4.248366013071895,
      "grad_norm": 3.129404306411743,
      "learning_rate": 1.3556317498794086e-05,
      "loss": 19.8903,
      "step": 1300
    },
    {
      "epoch": 4.248366013071895,
      "eval_loss": 5.158515930175781,
      "eval_runtime": 34.4934,
      "eval_samples_per_second": 3.943,
      "eval_steps_per_second": 0.493,
      "step": 1300
    },
    {
      "epoch": 4.264705882352941,
      "grad_norm": 6.264831066131592,
      "learning_rate": 1.3504931693879553e-05,
      "loss": 19.8027,
      "step": 1305
    },
    {
      "epoch": 4.281045751633987,
      "grad_norm": 5.9510817527771,
      "learning_rate": 1.3453440161905274e-05,
      "loss": 19.89,
      "step": 1310
    },
    {
      "epoch": 4.2973856209150325,
      "grad_norm": 7.387245178222656,
      "learning_rate": 1.3401844456125002e-05,
      "loss": 19.8977,
      "step": 1315
    },
    {
      "epoch": 4.313725490196078,
      "grad_norm": 5.019780158996582,
      "learning_rate": 1.33501461329349e-05,
      "loss": 19.7559,
      "step": 1320
    },
    {
      "epoch": 4.330065359477124,
      "grad_norm": 4.157130241394043,
      "learning_rate": 1.3298346751826624e-05,
      "loss": 19.661,
      "step": 1325
    },
    {
      "epoch": 4.34640522875817,
      "grad_norm": 4.0135884284973145,
      "learning_rate": 1.3246447875340249e-05,
      "loss": 19.8497,
      "step": 1330
    },
    {
      "epoch": 4.362745098039215,
      "grad_norm": 2.522993326187134,
      "learning_rate": 1.319445106901717e-05,
      "loss": 19.8546,
      "step": 1335
    },
    {
      "epoch": 4.379084967320262,
      "grad_norm": 7.064286231994629,
      "learning_rate": 1.3142357901352839e-05,
      "loss": 19.6965,
      "step": 1340
    },
    {
      "epoch": 4.395424836601308,
      "grad_norm": 7.051198482513428,
      "learning_rate": 1.3090169943749475e-05,
      "loss": 19.8943,
      "step": 1345
    },
    {
      "epoch": 4.411764705882353,
      "grad_norm": 4.534887313842773,
      "learning_rate": 1.3037888770468667e-05,
      "loss": 19.9795,
      "step": 1350
    },
    {
      "epoch": 4.411764705882353,
      "eval_loss": 5.149084568023682,
      "eval_runtime": 34.3717,
      "eval_samples_per_second": 3.957,
      "eval_steps_per_second": 0.495,
      "step": 1350
    },
    {
      "epoch": 4.428104575163399,
      "grad_norm": 1.8428770303726196,
      "learning_rate": 1.2985515958583865e-05,
      "loss": 19.7208,
      "step": 1355
    },
    {
      "epoch": 4.444444444444445,
      "grad_norm": 6.605807304382324,
      "learning_rate": 1.2933053087932821e-05,
      "loss": 19.9044,
      "step": 1360
    },
    {
      "epoch": 4.46078431372549,
      "grad_norm": 2.962801694869995,
      "learning_rate": 1.2880501741069931e-05,
      "loss": 19.638,
      "step": 1365
    },
    {
      "epoch": 4.477124183006536,
      "grad_norm": 5.54369592666626,
      "learning_rate": 1.2827863503218496e-05,
      "loss": 19.9236,
      "step": 1370
    },
    {
      "epoch": 4.493464052287582,
      "grad_norm": 4.999587059020996,
      "learning_rate": 1.2775139962222905e-05,
      "loss": 19.8062,
      "step": 1375
    },
    {
      "epoch": 4.509803921568627,
      "grad_norm": 10.197732925415039,
      "learning_rate": 1.272233270850073e-05,
      "loss": 19.8533,
      "step": 1380
    },
    {
      "epoch": 4.526143790849673,
      "grad_norm": 3.1204171180725098,
      "learning_rate": 1.2669443334994768e-05,
      "loss": 19.7291,
      "step": 1385
    },
    {
      "epoch": 4.542483660130719,
      "grad_norm": 6.466692924499512,
      "learning_rate": 1.2616473437124962e-05,
      "loss": 19.9082,
      "step": 1390
    },
    {
      "epoch": 4.5588235294117645,
      "grad_norm": 5.59208869934082,
      "learning_rate": 1.2563424612740307e-05,
      "loss": 19.8171,
      "step": 1395
    },
    {
      "epoch": 4.57516339869281,
      "grad_norm": 3.5732038021087646,
      "learning_rate": 1.2510298462070619e-05,
      "loss": 19.7291,
      "step": 1400
    },
    {
      "epoch": 4.57516339869281,
      "eval_loss": 5.154682159423828,
      "eval_runtime": 34.477,
      "eval_samples_per_second": 3.945,
      "eval_steps_per_second": 0.493,
      "step": 1400
    },
    {
      "epoch": 4.591503267973856,
      "grad_norm": 6.949134826660156,
      "learning_rate": 1.245709658767829e-05,
      "loss": 19.8039,
      "step": 1405
    },
    {
      "epoch": 4.607843137254902,
      "grad_norm": 2.2352776527404785,
      "learning_rate": 1.2403820594409926e-05,
      "loss": 19.8347,
      "step": 1410
    },
    {
      "epoch": 4.624183006535947,
      "grad_norm": 1.3226184844970703,
      "learning_rate": 1.2350472089347957e-05,
      "loss": 19.8816,
      "step": 1415
    },
    {
      "epoch": 4.640522875816993,
      "grad_norm": 7.3717827796936035,
      "learning_rate": 1.2297052681762143e-05,
      "loss": 19.8078,
      "step": 1420
    },
    {
      "epoch": 4.6568627450980395,
      "grad_norm": 7.534165382385254,
      "learning_rate": 1.2243563983061029e-05,
      "loss": 19.8765,
      "step": 1425
    },
    {
      "epoch": 4.673202614379085,
      "grad_norm": 3.4911415576934814,
      "learning_rate": 1.219000760674335e-05,
      "loss": 19.8518,
      "step": 1430
    },
    {
      "epoch": 4.689542483660131,
      "grad_norm": 1.6988989114761353,
      "learning_rate": 1.2136385168349345e-05,
      "loss": 19.8223,
      "step": 1435
    },
    {
      "epoch": 4.705882352941177,
      "grad_norm": 7.328236103057861,
      "learning_rate": 1.2082698285412037e-05,
      "loss": 19.7082,
      "step": 1440
    },
    {
      "epoch": 4.722222222222222,
      "grad_norm": 9.850829124450684,
      "learning_rate": 1.202894857740843e-05,
      "loss": 19.8405,
      "step": 1445
    },
    {
      "epoch": 4.738562091503268,
      "grad_norm": 8.07311725616455,
      "learning_rate": 1.1975137665710659e-05,
      "loss": 19.8831,
      "step": 1450
    },
    {
      "epoch": 4.738562091503268,
      "eval_loss": 5.161698341369629,
      "eval_runtime": 33.2535,
      "eval_samples_per_second": 4.09,
      "eval_steps_per_second": 0.511,
      "step": 1450
    },
    {
      "epoch": 4.754901960784314,
      "grad_norm": 4.196325778961182,
      "learning_rate": 1.1921267173537085e-05,
      "loss": 19.8622,
      "step": 1455
    },
    {
      "epoch": 4.771241830065359,
      "grad_norm": 3.960994005203247,
      "learning_rate": 1.1867338725903326e-05,
      "loss": 19.7357,
      "step": 1460
    },
    {
      "epoch": 4.787581699346405,
      "grad_norm": 7.0440897941589355,
      "learning_rate": 1.181335394957324e-05,
      "loss": 19.7383,
      "step": 1465
    },
    {
      "epoch": 4.803921568627451,
      "grad_norm": 3.4442009925842285,
      "learning_rate": 1.1759314473009855e-05,
      "loss": 19.8461,
      "step": 1470
    },
    {
      "epoch": 4.8202614379084965,
      "grad_norm": 4.027292728424072,
      "learning_rate": 1.170522192632624e-05,
      "loss": 19.8651,
      "step": 1475
    },
    {
      "epoch": 4.836601307189542,
      "grad_norm": 3.1317362785339355,
      "learning_rate": 1.1651077941236338e-05,
      "loss": 19.9037,
      "step": 1480
    },
    {
      "epoch": 4.852941176470588,
      "grad_norm": 7.646164894104004,
      "learning_rate": 1.1596884151005743e-05,
      "loss": 19.8857,
      "step": 1485
    },
    {
      "epoch": 4.8692810457516345,
      "grad_norm": 4.10695219039917,
      "learning_rate": 1.1542642190402434e-05,
      "loss": 19.85,
      "step": 1490
    },
    {
      "epoch": 4.88562091503268,
      "grad_norm": 4.141386032104492,
      "learning_rate": 1.1488353695647456e-05,
      "loss": 19.9063,
      "step": 1495
    },
    {
      "epoch": 4.901960784313726,
      "grad_norm": 5.103104114532471,
      "learning_rate": 1.1434020304365578e-05,
      "loss": 19.7921,
      "step": 1500
    },
    {
      "epoch": 4.901960784313726,
      "eval_loss": 5.157080173492432,
      "eval_runtime": 34.4483,
      "eval_samples_per_second": 3.948,
      "eval_steps_per_second": 0.493,
      "step": 1500
    },
    {
      "epoch": 4.9183006535947715,
      "grad_norm": 7.203105449676514,
      "learning_rate": 1.1379643655535869e-05,
      "loss": 19.7457,
      "step": 1505
    },
    {
      "epoch": 4.934640522875817,
      "grad_norm": 3.2250072956085205,
      "learning_rate": 1.1325225389442278e-05,
      "loss": 19.859,
      "step": 1510
    },
    {
      "epoch": 4.950980392156863,
      "grad_norm": 5.851444721221924,
      "learning_rate": 1.1270767147624146e-05,
      "loss": 19.8161,
      "step": 1515
    },
    {
      "epoch": 4.967320261437909,
      "grad_norm": 4.332499980926514,
      "learning_rate": 1.1216270572826697e-05,
      "loss": 19.8101,
      "step": 1520
    },
    {
      "epoch": 4.983660130718954,
      "grad_norm": 3.9711246490478516,
      "learning_rate": 1.1161737308951473e-05,
      "loss": 19.7985,
      "step": 1525
    },
    {
      "epoch": 5.0,
      "grad_norm": 7.5423479080200195,
      "learning_rate": 1.110716900100675e-05,
      "loss": 19.9568,
      "step": 1530
    },
    {
      "epoch": 5.016339869281046,
      "grad_norm": 4.642917156219482,
      "learning_rate": 1.1052567295057921e-05,
      "loss": 19.8427,
      "step": 1535
    },
    {
      "epoch": 5.032679738562091,
      "grad_norm": 1.1033844947814941,
      "learning_rate": 1.0997933838177828e-05,
      "loss": 19.8115,
      "step": 1540
    },
    {
      "epoch": 5.049019607843137,
      "grad_norm": 5.0876898765563965,
      "learning_rate": 1.0943270278397097e-05,
      "loss": 19.7476,
      "step": 1545
    },
    {
      "epoch": 5.065359477124183,
      "grad_norm": 1.2481688261032104,
      "learning_rate": 1.088857826465441e-05,
      "loss": 19.8341,
      "step": 1550
    },
    {
      "epoch": 5.065359477124183,
      "eval_loss": 5.15990686416626,
      "eval_runtime": 33.2824,
      "eval_samples_per_second": 4.086,
      "eval_steps_per_second": 0.511,
      "step": 1550
    },
    {
      "epoch": 5.0816993464052285,
      "grad_norm": 3.972989082336426,
      "learning_rate": 1.0833859446746773e-05,
      "loss": 19.8456,
      "step": 1555
    },
    {
      "epoch": 5.098039215686274,
      "grad_norm": 1.7823172807693481,
      "learning_rate": 1.0779115475279737e-05,
      "loss": 19.8832,
      "step": 1560
    },
    {
      "epoch": 5.11437908496732,
      "grad_norm": 3.777644634246826,
      "learning_rate": 1.0724348001617626e-05,
      "loss": 19.8648,
      "step": 1565
    },
    {
      "epoch": 5.130718954248366,
      "grad_norm": 5.328919887542725,
      "learning_rate": 1.0669558677833707e-05,
      "loss": 19.9311,
      "step": 1570
    },
    {
      "epoch": 5.147058823529412,
      "grad_norm": 2.525214195251465,
      "learning_rate": 1.0614749156660357e-05,
      "loss": 19.8032,
      "step": 1575
    },
    {
      "epoch": 5.163398692810458,
      "grad_norm": 4.710101127624512,
      "learning_rate": 1.0559921091439229e-05,
      "loss": 19.8569,
      "step": 1580
    },
    {
      "epoch": 5.1797385620915035,
      "grad_norm": 7.275094985961914,
      "learning_rate": 1.0505076136071342e-05,
      "loss": 19.8829,
      "step": 1585
    },
    {
      "epoch": 5.196078431372549,
      "grad_norm": 3.026651382446289,
      "learning_rate": 1.045021594496722e-05,
      "loss": 19.8984,
      "step": 1590
    },
    {
      "epoch": 5.212418300653595,
      "grad_norm": 1.9285268783569336,
      "learning_rate": 1.0395342172996969e-05,
      "loss": 19.8904,
      "step": 1595
    },
    {
      "epoch": 5.228758169934641,
      "grad_norm": 1.8924556970596313,
      "learning_rate": 1.034045647544038e-05,
      "loss": 19.7863,
      "step": 1600
    },
    {
      "epoch": 5.228758169934641,
      "eval_loss": 5.164814472198486,
      "eval_runtime": 33.1537,
      "eval_samples_per_second": 4.102,
      "eval_steps_per_second": 0.513,
      "step": 1600
    },
    {
      "epoch": 5.245098039215686,
      "grad_norm": 1.6428571939468384,
      "learning_rate": 1.0285560507936962e-05,
      "loss": 19.7277,
      "step": 1605
    },
    {
      "epoch": 5.261437908496732,
      "grad_norm": 3.486609697341919,
      "learning_rate": 1.0230655926436037e-05,
      "loss": 19.8007,
      "step": 1610
    },
    {
      "epoch": 5.277777777777778,
      "grad_norm": 3.190993309020996,
      "learning_rate": 1.0175744387146763e-05,
      "loss": 19.7906,
      "step": 1615
    },
    {
      "epoch": 5.294117647058823,
      "grad_norm": 4.740023136138916,
      "learning_rate": 1.0120827546488175e-05,
      "loss": 19.8564,
      "step": 1620
    },
    {
      "epoch": 5.310457516339869,
      "grad_norm": 2.5236470699310303,
      "learning_rate": 1.0065907061039234e-05,
      "loss": 19.826,
      "step": 1625
    },
    {
      "epoch": 5.326797385620915,
      "grad_norm": 6.921882152557373,
      "learning_rate": 1.0010984587488846e-05,
      "loss": 19.7911,
      "step": 1630
    },
    {
      "epoch": 5.3431372549019605,
      "grad_norm": 3.549344062805176,
      "learning_rate": 9.956061782585882e-06,
      "loss": 19.6784,
      "step": 1635
    },
    {
      "epoch": 5.359477124183006,
      "grad_norm": 2.49943470954895,
      "learning_rate": 9.901140303089216e-06,
      "loss": 19.8235,
      "step": 1640
    },
    {
      "epoch": 5.375816993464053,
      "grad_norm": 4.55495023727417,
      "learning_rate": 9.846221805717734e-06,
      "loss": 19.9402,
      "step": 1645
    },
    {
      "epoch": 5.392156862745098,
      "grad_norm": 1.1622883081436157,
      "learning_rate": 9.79130794710037e-06,
      "loss": 19.6843,
      "step": 1650
    },
    {
      "epoch": 5.392156862745098,
      "eval_loss": 5.169155120849609,
      "eval_runtime": 33.2761,
      "eval_samples_per_second": 4.087,
      "eval_steps_per_second": 0.511,
      "step": 1650
    },
    {
      "epoch": 5.408496732026144,
      "grad_norm": 5.284088134765625,
      "learning_rate": 9.736400383726138e-06,
      "loss": 19.8365,
      "step": 1655
    },
    {
      "epoch": 5.42483660130719,
      "grad_norm": 6.467616558074951,
      "learning_rate": 9.68150077189413e-06,
      "loss": 19.7541,
      "step": 1660
    },
    {
      "epoch": 5.4411764705882355,
      "grad_norm": 7.443348407745361,
      "learning_rate": 9.6266107676636e-06,
      "loss": 19.767,
      "step": 1665
    },
    {
      "epoch": 5.457516339869281,
      "grad_norm": 2.5204641819000244,
      "learning_rate": 9.571732026803978e-06,
      "loss": 19.8169,
      "step": 1670
    },
    {
      "epoch": 5.473856209150327,
      "grad_norm": 6.803286075592041,
      "learning_rate": 9.516866204744932e-06,
      "loss": 19.7481,
      "step": 1675
    },
    {
      "epoch": 5.490196078431373,
      "grad_norm": 3.4119038581848145,
      "learning_rate": 9.462014956526433e-06,
      "loss": 19.8292,
      "step": 1680
    },
    {
      "epoch": 5.506535947712418,
      "grad_norm": 1.6146034002304077,
      "learning_rate": 9.407179936748827e-06,
      "loss": 19.8185,
      "step": 1685
    },
    {
      "epoch": 5.522875816993464,
      "grad_norm": 4.227599620819092,
      "learning_rate": 9.352362799522925e-06,
      "loss": 19.8051,
      "step": 1690
    },
    {
      "epoch": 5.53921568627451,
      "grad_norm": 0.6792762279510498,
      "learning_rate": 9.297565198420112e-06,
      "loss": 19.8245,
      "step": 1695
    },
    {
      "epoch": 5.555555555555555,
      "grad_norm": 3.4708330631256104,
      "learning_rate": 9.24278878642246e-06,
      "loss": 19.9526,
      "step": 1700
    },
    {
      "epoch": 5.555555555555555,
      "eval_loss": 5.175923824310303,
      "eval_runtime": 33.2611,
      "eval_samples_per_second": 4.089,
      "eval_steps_per_second": 0.511,
      "step": 1700
    },
    {
      "epoch": 5.571895424836601,
      "grad_norm": 2.415286064147949,
      "learning_rate": 9.188035215872858e-06,
      "loss": 19.7409,
      "step": 1705
    },
    {
      "epoch": 5.588235294117647,
      "grad_norm": 2.685415029525757,
      "learning_rate": 9.133306138425186e-06,
      "loss": 19.7597,
      "step": 1710
    },
    {
      "epoch": 5.604575163398692,
      "grad_norm": 0.5932250022888184,
      "learning_rate": 9.078603204994484e-06,
      "loss": 19.8656,
      "step": 1715
    },
    {
      "epoch": 5.620915032679738,
      "grad_norm": 2.822845697402954,
      "learning_rate": 9.02392806570715e-06,
      "loss": 19.7909,
      "step": 1720
    },
    {
      "epoch": 5.637254901960784,
      "grad_norm": 4.069553852081299,
      "learning_rate": 8.969282369851163e-06,
      "loss": 19.6581,
      "step": 1725
    },
    {
      "epoch": 5.65359477124183,
      "grad_norm": 0.6393088698387146,
      "learning_rate": 8.91466776582634e-06,
      "loss": 19.8608,
      "step": 1730
    },
    {
      "epoch": 5.669934640522876,
      "grad_norm": 6.480313777923584,
      "learning_rate": 8.860085901094595e-06,
      "loss": 19.8879,
      "step": 1735
    },
    {
      "epoch": 5.686274509803922,
      "grad_norm": 0.5843682289123535,
      "learning_rate": 8.805538422130268e-06,
      "loss": 19.8411,
      "step": 1740
    },
    {
      "epoch": 5.7026143790849675,
      "grad_norm": 4.03074312210083,
      "learning_rate": 8.751026974370438e-06,
      "loss": 19.8155,
      "step": 1745
    },
    {
      "epoch": 5.718954248366013,
      "grad_norm": 2.6288280487060547,
      "learning_rate": 8.69655320216529e-06,
      "loss": 19.6897,
      "step": 1750
    },
    {
      "epoch": 5.718954248366013,
      "eval_loss": 5.176128387451172,
      "eval_runtime": 33.3444,
      "eval_samples_per_second": 4.079,
      "eval_steps_per_second": 0.51,
      "step": 1750
    },
    {
      "epoch": 5.735294117647059,
      "grad_norm": 5.155080318450928,
      "learning_rate": 8.64211874872852e-06,
      "loss": 19.8289,
      "step": 1755
    },
    {
      "epoch": 5.751633986928105,
      "grad_norm": 6.820042133331299,
      "learning_rate": 8.587725256087771e-06,
      "loss": 19.8236,
      "step": 1760
    },
    {
      "epoch": 5.76797385620915,
      "grad_norm": 2.4045534133911133,
      "learning_rate": 8.533374365035089e-06,
      "loss": 19.6951,
      "step": 1765
    },
    {
      "epoch": 5.784313725490196,
      "grad_norm": 0.3752513825893402,
      "learning_rate": 8.479067715077435e-06,
      "loss": 19.7438,
      "step": 1770
    },
    {
      "epoch": 5.800653594771242,
      "grad_norm": 1.629779577255249,
      "learning_rate": 8.424806944387219e-06,
      "loss": 19.7739,
      "step": 1775
    },
    {
      "epoch": 5.816993464052287,
      "grad_norm": 7.526909351348877,
      "learning_rate": 8.370593689752905e-06,
      "loss": 19.8203,
      "step": 1780
    },
    {
      "epoch": 5.833333333333333,
      "grad_norm": 4.476092338562012,
      "learning_rate": 8.316429586529616e-06,
      "loss": 19.8034,
      "step": 1785
    },
    {
      "epoch": 5.849673202614379,
      "grad_norm": 0.2929610013961792,
      "learning_rate": 8.262316268589815e-06,
      "loss": 19.7563,
      "step": 1790
    },
    {
      "epoch": 5.866013071895425,
      "grad_norm": 4.663789749145508,
      "learning_rate": 8.20825536827402e-06,
      "loss": 19.6778,
      "step": 1795
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 3.320524215698242,
      "learning_rate": 8.154248516341547e-06,
      "loss": 19.8615,
      "step": 1800
    },
    {
      "epoch": 5.882352941176471,
      "eval_loss": 5.168868064880371,
      "eval_runtime": 33.254,
      "eval_samples_per_second": 4.09,
      "eval_steps_per_second": 0.511,
      "step": 1800
    },
    {
      "epoch": 5.898692810457517,
      "grad_norm": 17.037919998168945,
      "learning_rate": 8.100297341921342e-06,
      "loss": 19.8863,
      "step": 1805
    },
    {
      "epoch": 5.915032679738562,
      "grad_norm": 4.028310298919678,
      "learning_rate": 8.046403472462818e-06,
      "loss": 19.7985,
      "step": 1810
    },
    {
      "epoch": 5.931372549019608,
      "grad_norm": 0.7259691953659058,
      "learning_rate": 7.992568533686782e-06,
      "loss": 19.7316,
      "step": 1815
    },
    {
      "epoch": 5.947712418300654,
      "grad_norm": 3.797856569290161,
      "learning_rate": 7.938794149536367e-06,
      "loss": 19.8218,
      "step": 1820
    },
    {
      "epoch": 5.9640522875816995,
      "grad_norm": 3.211419105529785,
      "learning_rate": 7.885081942128074e-06,
      "loss": 19.7325,
      "step": 1825
    },
    {
      "epoch": 5.980392156862745,
      "grad_norm": 1.6435091495513916,
      "learning_rate": 7.831433531702831e-06,
      "loss": 19.8495,
      "step": 1830
    },
    {
      "epoch": 5.996732026143791,
      "grad_norm": 1.673642635345459,
      "learning_rate": 7.777850536577104e-06,
      "loss": 19.8964,
      "step": 1835
    },
    {
      "epoch": 6.0130718954248366,
      "grad_norm": 3.546168088912964,
      "learning_rate": 7.724334573094101e-06,
      "loss": 19.8591,
      "step": 1840
    },
    {
      "epoch": 6.029411764705882,
      "grad_norm": 2.156477689743042,
      "learning_rate": 7.670887255575003e-06,
      "loss": 19.8133,
      "step": 1845
    },
    {
      "epoch": 6.045751633986928,
      "grad_norm": 0.8322875499725342,
      "learning_rate": 7.6175101962702624e-06,
      "loss": 19.7598,
      "step": 1850
    },
    {
      "epoch": 6.045751633986928,
      "eval_loss": 5.1748433113098145,
      "eval_runtime": 33.2437,
      "eval_samples_per_second": 4.091,
      "eval_steps_per_second": 0.511,
      "step": 1850
    },
    {
      "epoch": 6.062091503267974,
      "grad_norm": 2.832350492477417,
      "learning_rate": 7.56420500531099e-06,
      "loss": 19.7957,
      "step": 1855
    },
    {
      "epoch": 6.078431372549019,
      "grad_norm": 3.4800169467926025,
      "learning_rate": 7.510973290660366e-06,
      "loss": 19.7535,
      "step": 1860
    },
    {
      "epoch": 6.094771241830065,
      "grad_norm": 1.857887625694275,
      "learning_rate": 7.4578166580651335e-06,
      "loss": 19.7747,
      "step": 1865
    },
    {
      "epoch": 6.111111111111111,
      "grad_norm": 0.7523927688598633,
      "learning_rate": 7.404736711007176e-06,
      "loss": 19.8308,
      "step": 1870
    },
    {
      "epoch": 6.127450980392156,
      "grad_norm": 1.2841888666152954,
      "learning_rate": 7.3517350506551446e-06,
      "loss": 19.8759,
      "step": 1875
    },
    {
      "epoch": 6.143790849673203,
      "grad_norm": 0.9181450009346008,
      "learning_rate": 7.298813275816144e-06,
      "loss": 19.7892,
      "step": 1880
    },
    {
      "epoch": 6.160130718954249,
      "grad_norm": 3.1337568759918213,
      "learning_rate": 7.2459729828875256e-06,
      "loss": 19.823,
      "step": 1885
    },
    {
      "epoch": 6.176470588235294,
      "grad_norm": 6.401722431182861,
      "learning_rate": 7.193215765808703e-06,
      "loss": 19.703,
      "step": 1890
    },
    {
      "epoch": 6.19281045751634,
      "grad_norm": 1.658906102180481,
      "learning_rate": 7.140543216013109e-06,
      "loss": 19.7935,
      "step": 1895
    },
    {
      "epoch": 6.209150326797386,
      "grad_norm": 5.760620594024658,
      "learning_rate": 7.0879569223801526e-06,
      "loss": 19.8959,
      "step": 1900
    },
    {
      "epoch": 6.209150326797386,
      "eval_loss": 5.172486305236816,
      "eval_runtime": 33.2187,
      "eval_samples_per_second": 4.094,
      "eval_steps_per_second": 0.512,
      "step": 1900
    },
    {
      "epoch": 6.2254901960784315,
      "grad_norm": 2.0391407012939453,
      "learning_rate": 7.035458471187312e-06,
      "loss": 19.7841,
      "step": 1905
    },
    {
      "epoch": 6.241830065359477,
      "grad_norm": 2.4238715171813965,
      "learning_rate": 6.983049446062285e-06,
      "loss": 19.8549,
      "step": 1910
    },
    {
      "epoch": 6.258169934640523,
      "grad_norm": 0.8689526915550232,
      "learning_rate": 6.930731427935196e-06,
      "loss": 19.7699,
      "step": 1915
    },
    {
      "epoch": 6.2745098039215685,
      "grad_norm": 1.9728288650512695,
      "learning_rate": 6.878505994990935e-06,
      "loss": 19.8635,
      "step": 1920
    },
    {
      "epoch": 6.290849673202614,
      "grad_norm": 6.103767395019531,
      "learning_rate": 6.826374722621536e-06,
      "loss": 19.8825,
      "step": 1925
    },
    {
      "epoch": 6.30718954248366,
      "grad_norm": 1.985611915588379,
      "learning_rate": 6.774339183378663e-06,
      "loss": 19.7516,
      "step": 1930
    },
    {
      "epoch": 6.323529411764706,
      "grad_norm": 3.1306726932525635,
      "learning_rate": 6.7224009469261535e-06,
      "loss": 19.8652,
      "step": 1935
    },
    {
      "epoch": 6.339869281045751,
      "grad_norm": 1.5879957675933838,
      "learning_rate": 6.670561579992698e-06,
      "loss": 19.7305,
      "step": 1940
    },
    {
      "epoch": 6.356209150326797,
      "grad_norm": 1.56264066696167,
      "learning_rate": 6.618822646324563e-06,
      "loss": 19.7954,
      "step": 1945
    },
    {
      "epoch": 6.372549019607844,
      "grad_norm": 5.219336032867432,
      "learning_rate": 6.567185706638417e-06,
      "loss": 19.8341,
      "step": 1950
    },
    {
      "epoch": 6.372549019607844,
      "eval_loss": 5.182270526885986,
      "eval_runtime": 33.2183,
      "eval_samples_per_second": 4.094,
      "eval_steps_per_second": 0.512,
      "step": 1950
    },
    {
      "epoch": 6.388888888888889,
      "grad_norm": 2.3671419620513916,
      "learning_rate": 6.515652318574268e-06,
      "loss": 19.78,
      "step": 1955
    },
    {
      "epoch": 6.405228758169935,
      "grad_norm": 3.50958514213562,
      "learning_rate": 6.46422403664845e-06,
      "loss": 19.8811,
      "step": 1960
    },
    {
      "epoch": 6.421568627450981,
      "grad_norm": 5.430574417114258,
      "learning_rate": 6.41290241220676e-06,
      "loss": 19.7185,
      "step": 1965
    },
    {
      "epoch": 6.437908496732026,
      "grad_norm": 2.276231288909912,
      "learning_rate": 6.361688993377642e-06,
      "loss": 19.7859,
      "step": 1970
    },
    {
      "epoch": 6.454248366013072,
      "grad_norm": 0.18151280283927917,
      "learning_rate": 6.310585325025499e-06,
      "loss": 19.6966,
      "step": 1975
    },
    {
      "epoch": 6.470588235294118,
      "grad_norm": 4.1007561683654785,
      "learning_rate": 6.259592948704073e-06,
      "loss": 19.8293,
      "step": 1980
    },
    {
      "epoch": 6.4869281045751634,
      "grad_norm": 2.3025386333465576,
      "learning_rate": 6.208713402609968e-06,
      "loss": 19.7747,
      "step": 1985
    },
    {
      "epoch": 6.503267973856209,
      "grad_norm": 1.3353031873703003,
      "learning_rate": 6.157948221536237e-06,
      "loss": 19.7804,
      "step": 1990
    },
    {
      "epoch": 6.519607843137255,
      "grad_norm": 2.971698522567749,
      "learning_rate": 6.107298936826086e-06,
      "loss": 19.7779,
      "step": 1995
    },
    {
      "epoch": 6.5359477124183005,
      "grad_norm": 2.7225615978240967,
      "learning_rate": 6.0567670763266775e-06,
      "loss": 19.7595,
      "step": 2000
    },
    {
      "epoch": 6.5359477124183005,
      "eval_loss": 5.181980133056641,
      "eval_runtime": 33.2291,
      "eval_samples_per_second": 4.093,
      "eval_steps_per_second": 0.512,
      "step": 2000
    },
    {
      "epoch": 6.552287581699346,
      "grad_norm": 3.5568344593048096,
      "learning_rate": 6.006354164343047e-06,
      "loss": 19.7439,
      "step": 2005
    },
    {
      "epoch": 6.568627450980392,
      "grad_norm": 1.4490694999694824,
      "learning_rate": 5.956061721592121e-06,
      "loss": 19.6195,
      "step": 2010
    },
    {
      "epoch": 6.584967320261438,
      "grad_norm": 3.02957820892334,
      "learning_rate": 5.905891265156849e-06,
      "loss": 19.8676,
      "step": 2015
    },
    {
      "epoch": 6.601307189542483,
      "grad_norm": 0.7049852609634399,
      "learning_rate": 5.855844308440429e-06,
      "loss": 19.6877,
      "step": 2020
    },
    {
      "epoch": 6.617647058823529,
      "grad_norm": 0.6323133111000061,
      "learning_rate": 5.8059223611206716e-06,
      "loss": 19.7972,
      "step": 2025
    },
    {
      "epoch": 6.633986928104575,
      "grad_norm": 6.008154392242432,
      "learning_rate": 5.756126929104435e-06,
      "loss": 19.7809,
      "step": 2030
    },
    {
      "epoch": 6.650326797385621,
      "grad_norm": 4.006953239440918,
      "learning_rate": 5.706459514482226e-06,
      "loss": 19.8642,
      "step": 2035
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 0.8826864361763,
      "learning_rate": 5.6569216154828776e-06,
      "loss": 19.7751,
      "step": 2040
    },
    {
      "epoch": 6.683006535947713,
      "grad_norm": 3.7412450313568115,
      "learning_rate": 5.6075147264283526e-06,
      "loss": 19.8596,
      "step": 2045
    },
    {
      "epoch": 6.699346405228758,
      "grad_norm": 2.711379289627075,
      "learning_rate": 5.558240337688667e-06,
      "loss": 19.7847,
      "step": 2050
    },
    {
      "epoch": 6.699346405228758,
      "eval_loss": 5.192869186401367,
      "eval_runtime": 33.2186,
      "eval_samples_per_second": 4.094,
      "eval_steps_per_second": 0.512,
      "step": 2050
    },
    {
      "epoch": 6.715686274509804,
      "grad_norm": 7.223870754241943,
      "learning_rate": 5.509099935636932e-06,
      "loss": 19.8251,
      "step": 2055
    },
    {
      "epoch": 6.73202614379085,
      "grad_norm": 1.7809576988220215,
      "learning_rate": 5.460095002604533e-06,
      "loss": 19.7885,
      "step": 2060
    },
    {
      "epoch": 6.748366013071895,
      "grad_norm": 3.903959274291992,
      "learning_rate": 5.4112270168363854e-06,
      "loss": 19.8552,
      "step": 2065
    },
    {
      "epoch": 6.764705882352941,
      "grad_norm": 1.5007946491241455,
      "learning_rate": 5.362497452446379e-06,
      "loss": 19.6919,
      "step": 2070
    },
    {
      "epoch": 6.781045751633987,
      "grad_norm": 0.8756881952285767,
      "learning_rate": 5.313907779372862e-06,
      "loss": 19.7317,
      "step": 2075
    },
    {
      "epoch": 6.7973856209150325,
      "grad_norm": 7.7265944480896,
      "learning_rate": 5.265459463334361e-06,
      "loss": 19.8456,
      "step": 2080
    },
    {
      "epoch": 6.813725490196078,
      "grad_norm": 9.121688842773438,
      "learning_rate": 5.217153965785315e-06,
      "loss": 19.7793,
      "step": 2085
    },
    {
      "epoch": 6.830065359477124,
      "grad_norm": 2.222182512283325,
      "learning_rate": 5.168992743872019e-06,
      "loss": 19.7959,
      "step": 2090
    },
    {
      "epoch": 6.84640522875817,
      "grad_norm": 5.118831157684326,
      "learning_rate": 5.120977250388657e-06,
      "loss": 19.8273,
      "step": 2095
    },
    {
      "epoch": 6.862745098039216,
      "grad_norm": 0.36652833223342896,
      "learning_rate": 5.07310893373348e-06,
      "loss": 19.7189,
      "step": 2100
    },
    {
      "epoch": 6.862745098039216,
      "eval_loss": 5.187425136566162,
      "eval_runtime": 33.2038,
      "eval_samples_per_second": 4.096,
      "eval_steps_per_second": 0.512,
      "step": 2100
    },
    {
      "epoch": 6.879084967320262,
      "grad_norm": 2.0524747371673584,
      "learning_rate": 5.025389237865128e-06,
      "loss": 19.7957,
      "step": 2105
    },
    {
      "epoch": 6.895424836601308,
      "grad_norm": 5.184554100036621,
      "learning_rate": 4.977819602259048e-06,
      "loss": 19.8075,
      "step": 2110
    },
    {
      "epoch": 6.911764705882353,
      "grad_norm": 3.2221951484680176,
      "learning_rate": 4.930401461864099e-06,
      "loss": 19.745,
      "step": 2115
    },
    {
      "epoch": 6.928104575163399,
      "grad_norm": 2.9599106311798096,
      "learning_rate": 4.883136247059231e-06,
      "loss": 19.8015,
      "step": 2120
    },
    {
      "epoch": 6.944444444444445,
      "grad_norm": 7.066597938537598,
      "learning_rate": 4.836025383610382e-06,
      "loss": 19.8515,
      "step": 2125
    },
    {
      "epoch": 6.96078431372549,
      "grad_norm": 0.8710962533950806,
      "learning_rate": 4.78907029262743e-06,
      "loss": 19.8759,
      "step": 2130
    },
    {
      "epoch": 6.977124183006536,
      "grad_norm": 0.33073416352272034,
      "learning_rate": 4.742272390521354e-06,
      "loss": 19.717,
      "step": 2135
    },
    {
      "epoch": 6.993464052287582,
      "grad_norm": 4.566744327545166,
      "learning_rate": 4.695633088961487e-06,
      "loss": 19.8526,
      "step": 2140
    },
    {
      "epoch": 7.009803921568627,
      "grad_norm": 1.1168019771575928,
      "learning_rate": 4.649153794832939e-06,
      "loss": 19.7903,
      "step": 2145
    },
    {
      "epoch": 7.026143790849673,
      "grad_norm": 3.2686634063720703,
      "learning_rate": 4.602835910194165e-06,
      "loss": 19.8422,
      "step": 2150
    },
    {
      "epoch": 7.026143790849673,
      "eval_loss": 5.182363986968994,
      "eval_runtime": 33.1968,
      "eval_samples_per_second": 4.097,
      "eval_steps_per_second": 0.512,
      "step": 2150
    },
    {
      "epoch": 7.042483660130719,
      "grad_norm": 1.9339314699172974,
      "learning_rate": 4.556680832234657e-06,
      "loss": 19.7895,
      "step": 2155
    },
    {
      "epoch": 7.0588235294117645,
      "grad_norm": 0.915026843547821,
      "learning_rate": 4.5106899532328275e-06,
      "loss": 19.728,
      "step": 2160
    },
    {
      "epoch": 7.07516339869281,
      "grad_norm": 0.4027941823005676,
      "learning_rate": 4.4648646605139605e-06,
      "loss": 19.8241,
      "step": 2165
    },
    {
      "epoch": 7.091503267973856,
      "grad_norm": 1.7675824165344238,
      "learning_rate": 4.419206336408418e-06,
      "loss": 19.7198,
      "step": 2170
    },
    {
      "epoch": 7.107843137254902,
      "grad_norm": 1.8364683389663696,
      "learning_rate": 4.373716358209898e-06,
      "loss": 19.692,
      "step": 2175
    },
    {
      "epoch": 7.124183006535947,
      "grad_norm": 2.5283658504486084,
      "learning_rate": 4.328396098133921e-06,
      "loss": 19.9108,
      "step": 2180
    },
    {
      "epoch": 7.140522875816994,
      "grad_norm": 5.681760787963867,
      "learning_rate": 4.283246923276411e-06,
      "loss": 19.8204,
      "step": 2185
    },
    {
      "epoch": 7.1568627450980395,
      "grad_norm": 0.3774312734603882,
      "learning_rate": 4.2382701955724724e-06,
      "loss": 19.8229,
      "step": 2190
    },
    {
      "epoch": 7.173202614379085,
      "grad_norm": 0.9794401526451111,
      "learning_rate": 4.1934672717552986e-06,
      "loss": 19.7975,
      "step": 2195
    },
    {
      "epoch": 7.189542483660131,
      "grad_norm": 1.2676923274993896,
      "learning_rate": 4.1488395033152485e-06,
      "loss": 19.7658,
      "step": 2200
    },
    {
      "epoch": 7.189542483660131,
      "eval_loss": 5.193317413330078,
      "eval_runtime": 33.1549,
      "eval_samples_per_second": 4.102,
      "eval_steps_per_second": 0.513,
      "step": 2200
    },
    {
      "epoch": 7.205882352941177,
      "grad_norm": 0.46383580565452576,
      "learning_rate": 4.1043882364590895e-06,
      "loss": 19.645,
      "step": 2205
    },
    {
      "epoch": 7.222222222222222,
      "grad_norm": 7.723487377166748,
      "learning_rate": 4.060114812069367e-06,
      "loss": 19.8283,
      "step": 2210
    },
    {
      "epoch": 7.238562091503268,
      "grad_norm": 0.8493567705154419,
      "learning_rate": 4.016020565663974e-06,
      "loss": 19.7346,
      "step": 2215
    },
    {
      "epoch": 7.254901960784314,
      "grad_norm": 0.2985522449016571,
      "learning_rate": 3.972106827355852e-06,
      "loss": 19.7497,
      "step": 2220
    },
    {
      "epoch": 7.271241830065359,
      "grad_norm": 2.8080952167510986,
      "learning_rate": 3.9283749218128885e-06,
      "loss": 19.8009,
      "step": 2225
    },
    {
      "epoch": 7.287581699346405,
      "grad_norm": 0.6601187586784363,
      "learning_rate": 3.884826168217932e-06,
      "loss": 19.773,
      "step": 2230
    },
    {
      "epoch": 7.303921568627451,
      "grad_norm": 3.708355188369751,
      "learning_rate": 3.841461880229015e-06,
      "loss": 19.6981,
      "step": 2235
    },
    {
      "epoch": 7.3202614379084965,
      "grad_norm": 0.8459839820861816,
      "learning_rate": 3.79828336593972e-06,
      "loss": 19.8981,
      "step": 2240
    },
    {
      "epoch": 7.336601307189542,
      "grad_norm": 1.287186622619629,
      "learning_rate": 3.7552919278397335e-06,
      "loss": 19.8492,
      "step": 2245
    },
    {
      "epoch": 7.352941176470588,
      "grad_norm": 2.896367073059082,
      "learning_rate": 3.7124888627755375e-06,
      "loss": 19.7022,
      "step": 2250
    },
    {
      "epoch": 7.352941176470588,
      "eval_loss": 5.189843654632568,
      "eval_runtime": 33.2466,
      "eval_samples_per_second": 4.091,
      "eval_steps_per_second": 0.511,
      "step": 2250
    },
    {
      "epoch": 7.3692810457516345,
      "grad_norm": 0.24064093828201294,
      "learning_rate": 3.6698754619112974e-06,
      "loss": 19.7689,
      "step": 2255
    },
    {
      "epoch": 7.38562091503268,
      "grad_norm": 3.615546226501465,
      "learning_rate": 3.627453010689922e-06,
      "loss": 19.7909,
      "step": 2260
    },
    {
      "epoch": 7.401960784313726,
      "grad_norm": 0.3866567611694336,
      "learning_rate": 3.5852227887942713e-06,
      "loss": 19.7482,
      "step": 2265
    },
    {
      "epoch": 7.4183006535947715,
      "grad_norm": 3.551166534423828,
      "learning_rate": 3.5431860701085785e-06,
      "loss": 19.8059,
      "step": 2270
    },
    {
      "epoch": 7.434640522875817,
      "grad_norm": 1.1033893823623657,
      "learning_rate": 3.501344122679995e-06,
      "loss": 19.8245,
      "step": 2275
    },
    {
      "epoch": 7.450980392156863,
      "grad_norm": 2.544363260269165,
      "learning_rate": 3.4596982086803597e-06,
      "loss": 19.7993,
      "step": 2280
    },
    {
      "epoch": 7.467320261437909,
      "grad_norm": 1.4685626029968262,
      "learning_rate": 3.4182495843681117e-06,
      "loss": 19.7884,
      "step": 2285
    },
    {
      "epoch": 7.483660130718954,
      "grad_norm": 0.7012608647346497,
      "learning_rate": 3.3769995000504153e-06,
      "loss": 19.7269,
      "step": 2290
    },
    {
      "epoch": 7.5,
      "grad_norm": 2.527374267578125,
      "learning_rate": 3.3359492000454186e-06,
      "loss": 19.7279,
      "step": 2295
    },
    {
      "epoch": 7.516339869281046,
      "grad_norm": 0.9904648661613464,
      "learning_rate": 3.2950999226447356e-06,
      "loss": 19.8158,
      "step": 2300
    },
    {
      "epoch": 7.516339869281046,
      "eval_loss": 5.1951518058776855,
      "eval_runtime": 33.1598,
      "eval_samples_per_second": 4.101,
      "eval_steps_per_second": 0.513,
      "step": 2300
    },
    {
      "epoch": 7.532679738562091,
      "grad_norm": 0.18201357126235962,
      "learning_rate": 3.254452900076083e-06,
      "loss": 19.7671,
      "step": 2305
    },
    {
      "epoch": 7.549019607843137,
      "grad_norm": 2.120907783508301,
      "learning_rate": 3.2140093584661247e-06,
      "loss": 19.7662,
      "step": 2310
    },
    {
      "epoch": 7.565359477124183,
      "grad_norm": 0.7815133333206177,
      "learning_rate": 3.173770517803467e-06,
      "loss": 19.8118,
      "step": 2315
    },
    {
      "epoch": 7.5816993464052285,
      "grad_norm": 0.9182320833206177,
      "learning_rate": 3.133737591901864e-06,
      "loss": 19.8238,
      "step": 2320
    },
    {
      "epoch": 7.598039215686274,
      "grad_norm": 0.4282200038433075,
      "learning_rate": 3.093911788363617e-06,
      "loss": 19.7532,
      "step": 2325
    },
    {
      "epoch": 7.61437908496732,
      "grad_norm": 4.212863922119141,
      "learning_rate": 3.0542943085431144e-06,
      "loss": 19.8599,
      "step": 2330
    },
    {
      "epoch": 7.6307189542483655,
      "grad_norm": 1.648912787437439,
      "learning_rate": 3.0148863475106315e-06,
      "loss": 19.8015,
      "step": 2335
    },
    {
      "epoch": 7.647058823529412,
      "grad_norm": 0.8521828055381775,
      "learning_rate": 2.9756890940162476e-06,
      "loss": 19.7162,
      "step": 2340
    },
    {
      "epoch": 7.663398692810458,
      "grad_norm": 0.17969545722007751,
      "learning_rate": 2.936703730454017e-06,
      "loss": 19.7832,
      "step": 2345
    },
    {
      "epoch": 7.6797385620915035,
      "grad_norm": 0.8010191321372986,
      "learning_rate": 2.897931432826264e-06,
      "loss": 19.7302,
      "step": 2350
    },
    {
      "epoch": 7.6797385620915035,
      "eval_loss": 5.1911396980285645,
      "eval_runtime": 33.1769,
      "eval_samples_per_second": 4.099,
      "eval_steps_per_second": 0.512,
      "step": 2350
    },
    {
      "epoch": 7.696078431372549,
      "grad_norm": 0.3834933638572693,
      "learning_rate": 2.8593733707081516e-06,
      "loss": 19.8127,
      "step": 2355
    },
    {
      "epoch": 7.712418300653595,
      "grad_norm": 4.111655235290527,
      "learning_rate": 2.82103070721237e-06,
      "loss": 19.9134,
      "step": 2360
    },
    {
      "epoch": 7.728758169934641,
      "grad_norm": 2.086026430130005,
      "learning_rate": 2.7829045989540594e-06,
      "loss": 19.6861,
      "step": 2365
    },
    {
      "epoch": 7.745098039215686,
      "grad_norm": 4.541070461273193,
      "learning_rate": 2.7449961960159345e-06,
      "loss": 19.8916,
      "step": 2370
    },
    {
      "epoch": 7.761437908496732,
      "grad_norm": 1.7570289373397827,
      "learning_rate": 2.707306641913556e-06,
      "loss": 19.7331,
      "step": 2375
    },
    {
      "epoch": 7.777777777777778,
      "grad_norm": 0.4119231402873993,
      "learning_rate": 2.669837073560887e-06,
      "loss": 19.8203,
      "step": 2380
    },
    {
      "epoch": 7.794117647058823,
      "grad_norm": 2.3220038414001465,
      "learning_rate": 2.6325886212359496e-06,
      "loss": 19.8592,
      "step": 2385
    },
    {
      "epoch": 7.810457516339869,
      "grad_norm": 1.637740135192871,
      "learning_rate": 2.59556240854677e-06,
      "loss": 19.7549,
      "step": 2390
    },
    {
      "epoch": 7.826797385620915,
      "grad_norm": 6.218803882598877,
      "learning_rate": 2.5587595523974408e-06,
      "loss": 19.7633,
      "step": 2395
    },
    {
      "epoch": 7.8431372549019605,
      "grad_norm": 1.7311596870422363,
      "learning_rate": 2.5221811629544768e-06,
      "loss": 19.7506,
      "step": 2400
    },
    {
      "epoch": 7.8431372549019605,
      "eval_loss": 5.191634178161621,
      "eval_runtime": 33.2826,
      "eval_samples_per_second": 4.086,
      "eval_steps_per_second": 0.511,
      "step": 2400
    },
    {
      "epoch": 7.859477124183007,
      "grad_norm": 0.20457522571086884,
      "learning_rate": 2.485828343613288e-06,
      "loss": 19.8516,
      "step": 2405
    },
    {
      "epoch": 7.875816993464053,
      "grad_norm": 0.30602455139160156,
      "learning_rate": 2.4497021909649252e-06,
      "loss": 19.7583,
      "step": 2410
    },
    {
      "epoch": 7.892156862745098,
      "grad_norm": 3.031836748123169,
      "learning_rate": 2.4138037947629743e-06,
      "loss": 19.8771,
      "step": 2415
    },
    {
      "epoch": 7.908496732026144,
      "grad_norm": 0.792105495929718,
      "learning_rate": 2.3781342378907036e-06,
      "loss": 19.7648,
      "step": 2420
    },
    {
      "epoch": 7.92483660130719,
      "grad_norm": 3.58561372756958,
      "learning_rate": 2.3426945963283853e-06,
      "loss": 19.7219,
      "step": 2425
    },
    {
      "epoch": 7.9411764705882355,
      "grad_norm": 1.3959503173828125,
      "learning_rate": 2.3074859391208494e-06,
      "loss": 19.6921,
      "step": 2430
    },
    {
      "epoch": 7.957516339869281,
      "grad_norm": 0.5335241556167603,
      "learning_rate": 2.2725093283452305e-06,
      "loss": 19.8216,
      "step": 2435
    },
    {
      "epoch": 7.973856209150327,
      "grad_norm": 3.181443691253662,
      "learning_rate": 2.2377658190789263e-06,
      "loss": 19.8524,
      "step": 2440
    },
    {
      "epoch": 7.990196078431373,
      "grad_norm": 5.184859752655029,
      "learning_rate": 2.2032564593677773e-06,
      "loss": 19.7536,
      "step": 2445
    },
    {
      "epoch": 8.006535947712418,
      "grad_norm": 2.005329132080078,
      "learning_rate": 2.1689822901944456e-06,
      "loss": 19.7734,
      "step": 2450
    },
    {
      "epoch": 8.006535947712418,
      "eval_loss": 5.191656112670898,
      "eval_runtime": 34.7459,
      "eval_samples_per_second": 3.914,
      "eval_steps_per_second": 0.489,
      "step": 2450
    },
    {
      "epoch": 8.022875816993464,
      "grad_norm": 0.37699010968208313,
      "learning_rate": 2.1349443454470254e-06,
      "loss": 19.8261,
      "step": 2455
    },
    {
      "epoch": 8.03921568627451,
      "grad_norm": 0.3176310956478119,
      "learning_rate": 2.10114365188784e-06,
      "loss": 19.7532,
      "step": 2460
    },
    {
      "epoch": 8.055555555555555,
      "grad_norm": 0.341506689786911,
      "learning_rate": 2.0675812291224796e-06,
      "loss": 19.8056,
      "step": 2465
    },
    {
      "epoch": 8.071895424836601,
      "grad_norm": 0.7428163886070251,
      "learning_rate": 2.034258089569041e-06,
      "loss": 19.7533,
      "step": 2470
    },
    {
      "epoch": 8.088235294117647,
      "grad_norm": 0.4901532828807831,
      "learning_rate": 2.0011752384275862e-06,
      "loss": 19.7624,
      "step": 2475
    },
    {
      "epoch": 8.104575163398692,
      "grad_norm": 0.3366042971611023,
      "learning_rate": 1.9683336736498326e-06,
      "loss": 19.8333,
      "step": 2480
    },
    {
      "epoch": 8.120915032679738,
      "grad_norm": 1.8547319173812866,
      "learning_rate": 1.935734385909028e-06,
      "loss": 19.7924,
      "step": 2485
    },
    {
      "epoch": 8.137254901960784,
      "grad_norm": 0.23366406559944153,
      "learning_rate": 1.9033783585700848e-06,
      "loss": 19.8201,
      "step": 2490
    },
    {
      "epoch": 8.15359477124183,
      "grad_norm": 1.689406156539917,
      "learning_rate": 1.871266567659905e-06,
      "loss": 19.6794,
      "step": 2495
    },
    {
      "epoch": 8.169934640522875,
      "grad_norm": 0.14531520009040833,
      "learning_rate": 1.8393999818379527e-06,
      "loss": 19.8376,
      "step": 2500
    },
    {
      "epoch": 8.169934640522875,
      "eval_loss": 5.195398807525635,
      "eval_runtime": 34.6601,
      "eval_samples_per_second": 3.924,
      "eval_steps_per_second": 0.49,
      "step": 2500
    },
    {
      "epoch": 8.186274509803921,
      "grad_norm": 4.769265651702881,
      "learning_rate": 1.8077795623670135e-06,
      "loss": 19.8091,
      "step": 2505
    },
    {
      "epoch": 8.202614379084967,
      "grad_norm": 0.8785268068313599,
      "learning_rate": 1.7764062630842226e-06,
      "loss": 19.7747,
      "step": 2510
    },
    {
      "epoch": 8.218954248366012,
      "grad_norm": 0.9909743070602417,
      "learning_rate": 1.74528103037226e-06,
      "loss": 19.7462,
      "step": 2515
    },
    {
      "epoch": 8.235294117647058,
      "grad_norm": 1.6449761390686035,
      "learning_rate": 1.7144048031308414e-06,
      "loss": 19.8082,
      "step": 2520
    },
    {
      "epoch": 8.251633986928105,
      "grad_norm": 4.151368141174316,
      "learning_rate": 1.683778512748362e-06,
      "loss": 19.7794,
      "step": 2525
    },
    {
      "epoch": 8.267973856209151,
      "grad_norm": 0.5087878108024597,
      "learning_rate": 1.6534030830738212e-06,
      "loss": 19.7208,
      "step": 2530
    },
    {
      "epoch": 8.284313725490197,
      "grad_norm": 0.5382348895072937,
      "learning_rate": 1.6232794303889466e-06,
      "loss": 19.8269,
      "step": 2535
    },
    {
      "epoch": 8.300653594771243,
      "grad_norm": 0.6211628317832947,
      "learning_rate": 1.5934084633805536e-06,
      "loss": 19.7668,
      "step": 2540
    },
    {
      "epoch": 8.316993464052288,
      "grad_norm": 0.7124184370040894,
      "learning_rate": 1.563791083113142e-06,
      "loss": 19.8693,
      "step": 2545
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 0.14434728026390076,
      "learning_rate": 1.534428183001705e-06,
      "loss": 19.7867,
      "step": 2550
    },
    {
      "epoch": 8.333333333333334,
      "eval_loss": 5.194728851318359,
      "eval_runtime": 34.7524,
      "eval_samples_per_second": 3.913,
      "eval_steps_per_second": 0.489,
      "step": 2550
    },
    {
      "epoch": 8.34967320261438,
      "grad_norm": 3.289508104324341,
      "learning_rate": 1.5053206487847916e-06,
      "loss": 19.6777,
      "step": 2555
    },
    {
      "epoch": 8.366013071895425,
      "grad_norm": 0.33321669697761536,
      "learning_rate": 1.4764693584977663e-06,
      "loss": 19.7198,
      "step": 2560
    },
    {
      "epoch": 8.382352941176471,
      "grad_norm": 3.3151285648345947,
      "learning_rate": 1.4478751824463543e-06,
      "loss": 19.6655,
      "step": 2565
    },
    {
      "epoch": 8.398692810457517,
      "grad_norm": 1.8595610857009888,
      "learning_rate": 1.4195389831803596e-06,
      "loss": 19.834,
      "step": 2570
    },
    {
      "epoch": 8.415032679738562,
      "grad_norm": 4.206405162811279,
      "learning_rate": 1.391461615467663e-06,
      "loss": 19.7527,
      "step": 2575
    },
    {
      "epoch": 8.431372549019608,
      "grad_norm": 0.7878736257553101,
      "learning_rate": 1.3636439262684299e-06,
      "loss": 19.739,
      "step": 2580
    },
    {
      "epoch": 8.447712418300654,
      "grad_norm": 0.9615802764892578,
      "learning_rate": 1.336086754709569e-06,
      "loss": 19.7361,
      "step": 2585
    },
    {
      "epoch": 8.4640522875817,
      "grad_norm": 0.8893600702285767,
      "learning_rate": 1.3087909320594128e-06,
      "loss": 19.8621,
      "step": 2590
    },
    {
      "epoch": 8.480392156862745,
      "grad_norm": 0.20747025310993195,
      "learning_rate": 1.2817572817026402e-06,
      "loss": 19.7771,
      "step": 2595
    },
    {
      "epoch": 8.49673202614379,
      "grad_norm": 1.1014832258224487,
      "learning_rate": 1.2549866191154547e-06,
      "loss": 19.868,
      "step": 2600
    },
    {
      "epoch": 8.49673202614379,
      "eval_loss": 5.196037769317627,
      "eval_runtime": 34.7798,
      "eval_samples_per_second": 3.91,
      "eval_steps_per_second": 0.489,
      "step": 2600
    },
    {
      "epoch": 8.513071895424837,
      "grad_norm": 0.5388965606689453,
      "learning_rate": 1.2284797518409575e-06,
      "loss": 19.7718,
      "step": 2605
    },
    {
      "epoch": 8.529411764705882,
      "grad_norm": 0.5627431869506836,
      "learning_rate": 1.2022374794648229e-06,
      "loss": 19.7915,
      "step": 2610
    },
    {
      "epoch": 8.545751633986928,
      "grad_norm": 0.4081428647041321,
      "learning_rate": 1.1762605935911432e-06,
      "loss": 19.785,
      "step": 2615
    },
    {
      "epoch": 8.562091503267974,
      "grad_norm": 0.7202368378639221,
      "learning_rate": 1.150549877818581e-06,
      "loss": 19.7902,
      "step": 2620
    },
    {
      "epoch": 8.57843137254902,
      "grad_norm": 0.4965018630027771,
      "learning_rate": 1.125106107716708e-06,
      "loss": 19.9163,
      "step": 2625
    },
    {
      "epoch": 8.594771241830065,
      "grad_norm": 0.4691354036331177,
      "learning_rate": 1.099930050802621e-06,
      "loss": 19.7726,
      "step": 2630
    },
    {
      "epoch": 8.61111111111111,
      "grad_norm": 2.9391090869903564,
      "learning_rate": 1.075022466517791e-06,
      "loss": 19.7407,
      "step": 2635
    },
    {
      "epoch": 8.627450980392156,
      "grad_norm": 1.760296106338501,
      "learning_rate": 1.0503841062051445e-06,
      "loss": 19.742,
      "step": 2640
    },
    {
      "epoch": 8.643790849673202,
      "grad_norm": 0.7135276198387146,
      "learning_rate": 1.0260157130864178e-06,
      "loss": 19.7315,
      "step": 2645
    },
    {
      "epoch": 8.660130718954248,
      "grad_norm": 1.1431361436843872,
      "learning_rate": 1.0019180222397095e-06,
      "loss": 19.7142,
      "step": 2650
    },
    {
      "epoch": 8.660130718954248,
      "eval_loss": 5.195533752441406,
      "eval_runtime": 33.091,
      "eval_samples_per_second": 4.11,
      "eval_steps_per_second": 0.514,
      "step": 2650
    },
    {
      "epoch": 8.676470588235293,
      "grad_norm": 0.3882811665534973,
      "learning_rate": 9.780917605773376e-07,
      "loss": 19.7147,
      "step": 2655
    },
    {
      "epoch": 8.69281045751634,
      "grad_norm": 1.2727855443954468,
      "learning_rate": 9.545376468238864e-07,
      "loss": 19.776,
      "step": 2660
    },
    {
      "epoch": 8.709150326797385,
      "grad_norm": 1.8581891059875488,
      "learning_rate": 9.312563914945461e-07,
      "loss": 19.8097,
      "step": 2665
    },
    {
      "epoch": 8.72549019607843,
      "grad_norm": 1.4337044954299927,
      "learning_rate": 9.082486968736614e-07,
      "loss": 19.7084,
      "step": 2670
    },
    {
      "epoch": 8.741830065359476,
      "grad_norm": 0.741115152835846,
      "learning_rate": 8.855152569935632e-07,
      "loss": 19.8475,
      "step": 2675
    },
    {
      "epoch": 8.758169934640524,
      "grad_norm": 0.5862143635749817,
      "learning_rate": 8.630567576136196e-07,
      "loss": 19.7224,
      "step": 2680
    },
    {
      "epoch": 8.77450980392157,
      "grad_norm": 0.4725935161113739,
      "learning_rate": 8.40873876199565e-07,
      "loss": 19.762,
      "step": 2685
    },
    {
      "epoch": 8.790849673202615,
      "grad_norm": 2.352754831314087,
      "learning_rate": 8.189672819030459e-07,
      "loss": 19.7851,
      "step": 2690
    },
    {
      "epoch": 8.80718954248366,
      "grad_norm": 1.728451132774353,
      "learning_rate": 7.97337635541452e-07,
      "loss": 19.7525,
      "step": 2695
    },
    {
      "epoch": 8.823529411764707,
      "grad_norm": 4.68741512298584,
      "learning_rate": 7.759855895779711e-07,
      "loss": 19.7807,
      "step": 2700
    },
    {
      "epoch": 8.823529411764707,
      "eval_loss": 5.197226047515869,
      "eval_runtime": 34.2871,
      "eval_samples_per_second": 3.967,
      "eval_steps_per_second": 0.496,
      "step": 2700
    },
    {
      "epoch": 8.839869281045752,
      "grad_norm": 0.2611408531665802,
      "learning_rate": 7.549117881019141e-07,
      "loss": 19.8885,
      "step": 2705
    },
    {
      "epoch": 8.856209150326798,
      "grad_norm": 0.5205100178718567,
      "learning_rate": 7.341168668092857e-07,
      "loss": 19.8995,
      "step": 2710
    },
    {
      "epoch": 8.872549019607844,
      "grad_norm": 4.355475425720215,
      "learning_rate": 7.136014529836033e-07,
      "loss": 19.8558,
      "step": 2715
    },
    {
      "epoch": 8.88888888888889,
      "grad_norm": 0.40176770091056824,
      "learning_rate": 6.933661654769797e-07,
      "loss": 19.6928,
      "step": 2720
    },
    {
      "epoch": 8.905228758169935,
      "grad_norm": 2.103443145751953,
      "learning_rate": 6.734116146914516e-07,
      "loss": 19.7134,
      "step": 2725
    },
    {
      "epoch": 8.92156862745098,
      "grad_norm": 3.792872667312622,
      "learning_rate": 6.537384025605742e-07,
      "loss": 19.9006,
      "step": 2730
    },
    {
      "epoch": 8.937908496732026,
      "grad_norm": 0.3889846205711365,
      "learning_rate": 6.343471225312536e-07,
      "loss": 19.8429,
      "step": 2735
    },
    {
      "epoch": 8.954248366013072,
      "grad_norm": 2.079909324645996,
      "learning_rate": 6.1523835954585e-07,
      "loss": 19.734,
      "step": 2740
    },
    {
      "epoch": 8.970588235294118,
      "grad_norm": 1.369265079498291,
      "learning_rate": 5.964126900245359e-07,
      "loss": 19.7606,
      "step": 2745
    },
    {
      "epoch": 8.986928104575163,
      "grad_norm": 3.5336568355560303,
      "learning_rate": 5.778706818479007e-07,
      "loss": 19.7421,
      "step": 2750
    },
    {
      "epoch": 8.986928104575163,
      "eval_loss": 5.197963714599609,
      "eval_runtime": 34.2511,
      "eval_samples_per_second": 3.971,
      "eval_steps_per_second": 0.496,
      "step": 2750
    },
    {
      "epoch": 9.00326797385621,
      "grad_norm": 0.4437856674194336,
      "learning_rate": 5.596128943398316e-07,
      "loss": 19.8074,
      "step": 2755
    },
    {
      "epoch": 9.019607843137255,
      "grad_norm": 2.779848575592041,
      "learning_rate": 5.416398782506294e-07,
      "loss": 19.7911,
      "step": 2760
    },
    {
      "epoch": 9.0359477124183,
      "grad_norm": 0.9459887742996216,
      "learning_rate": 5.23952175740402e-07,
      "loss": 19.8141,
      "step": 2765
    },
    {
      "epoch": 9.052287581699346,
      "grad_norm": 0.6099362969398499,
      "learning_rate": 5.065503203627076e-07,
      "loss": 19.8603,
      "step": 2770
    },
    {
      "epoch": 9.068627450980392,
      "grad_norm": 0.4565660357475281,
      "learning_rate": 4.894348370484648e-07,
      "loss": 19.7777,
      "step": 2775
    },
    {
      "epoch": 9.084967320261438,
      "grad_norm": 0.9456712603569031,
      "learning_rate": 4.7260624209010675e-07,
      "loss": 19.6886,
      "step": 2780
    },
    {
      "epoch": 9.101307189542483,
      "grad_norm": 0.7779245972633362,
      "learning_rate": 4.5606504312602384e-07,
      "loss": 19.7437,
      "step": 2785
    },
    {
      "epoch": 9.117647058823529,
      "grad_norm": 2.9464974403381348,
      "learning_rate": 4.398117391252299e-07,
      "loss": 19.7543,
      "step": 2790
    },
    {
      "epoch": 9.133986928104575,
      "grad_norm": 0.41149207949638367,
      "learning_rate": 4.2384682037233115e-07,
      "loss": 19.8074,
      "step": 2795
    },
    {
      "epoch": 9.15032679738562,
      "grad_norm": 2.870779275894165,
      "learning_rate": 4.081707684527236e-07,
      "loss": 19.7683,
      "step": 2800
    },
    {
      "epoch": 9.15032679738562,
      "eval_loss": 5.199377536773682,
      "eval_runtime": 34.0681,
      "eval_samples_per_second": 3.992,
      "eval_steps_per_second": 0.499,
      "step": 2800
    },
    {
      "epoch": 9.166666666666666,
      "grad_norm": 0.2523391842842102,
      "learning_rate": 3.9278405623806914e-07,
      "loss": 19.7191,
      "step": 2805
    },
    {
      "epoch": 9.183006535947712,
      "grad_norm": 0.6428676247596741,
      "learning_rate": 3.776871478720334e-07,
      "loss": 19.7417,
      "step": 2810
    },
    {
      "epoch": 9.199346405228757,
      "grad_norm": 0.20742954313755035,
      "learning_rate": 3.628804987562795e-07,
      "loss": 19.603,
      "step": 2815
    },
    {
      "epoch": 9.215686274509803,
      "grad_norm": 0.14737223088741302,
      "learning_rate": 3.483645555367421e-07,
      "loss": 19.8169,
      "step": 2820
    },
    {
      "epoch": 9.232026143790849,
      "grad_norm": 0.5067331790924072,
      "learning_rate": 3.3413975609013713e-07,
      "loss": 19.6937,
      "step": 2825
    },
    {
      "epoch": 9.248366013071895,
      "grad_norm": 0.5444879531860352,
      "learning_rate": 3.2020652951077256e-07,
      "loss": 19.7684,
      "step": 2830
    },
    {
      "epoch": 9.264705882352942,
      "grad_norm": 1.7591767311096191,
      "learning_rate": 3.06565296097584e-07,
      "loss": 19.7525,
      "step": 2835
    },
    {
      "epoch": 9.281045751633988,
      "grad_norm": 0.43305861949920654,
      "learning_rate": 2.93216467341475e-07,
      "loss": 19.7423,
      "step": 2840
    },
    {
      "epoch": 9.297385620915033,
      "grad_norm": 0.49545446038246155,
      "learning_rate": 2.801604459128926e-07,
      "loss": 19.8511,
      "step": 2845
    },
    {
      "epoch": 9.313725490196079,
      "grad_norm": 0.19162750244140625,
      "learning_rate": 2.6739762564968686e-07,
      "loss": 19.5367,
      "step": 2850
    },
    {
      "epoch": 9.313725490196079,
      "eval_loss": 5.198339462280273,
      "eval_runtime": 34.2792,
      "eval_samples_per_second": 3.967,
      "eval_steps_per_second": 0.496,
      "step": 2850
    },
    {
      "epoch": 9.330065359477125,
      "grad_norm": 0.48532313108444214,
      "learning_rate": 2.5492839154522495e-07,
      "loss": 19.8542,
      "step": 2855
    },
    {
      "epoch": 9.34640522875817,
      "grad_norm": 0.5418296456336975,
      "learning_rate": 2.4275311973678384e-07,
      "loss": 19.8149,
      "step": 2860
    },
    {
      "epoch": 9.362745098039216,
      "grad_norm": 2.353667974472046,
      "learning_rate": 2.308721774941991e-07,
      "loss": 19.9004,
      "step": 2865
    },
    {
      "epoch": 9.379084967320262,
      "grad_norm": 0.33897674083709717,
      "learning_rate": 2.192859232087885e-07,
      "loss": 19.7402,
      "step": 2870
    },
    {
      "epoch": 9.395424836601308,
      "grad_norm": 1.590867042541504,
      "learning_rate": 2.079947063825427e-07,
      "loss": 19.8013,
      "step": 2875
    },
    {
      "epoch": 9.411764705882353,
      "grad_norm": 2.297924041748047,
      "learning_rate": 1.9699886761757826e-07,
      "loss": 19.7613,
      "step": 2880
    },
    {
      "epoch": 9.428104575163399,
      "grad_norm": 2.9094021320343018,
      "learning_rate": 1.8629873860586567e-07,
      "loss": 19.8409,
      "step": 2885
    },
    {
      "epoch": 9.444444444444445,
      "grad_norm": 0.7594155073165894,
      "learning_rate": 1.7589464211922537e-07,
      "loss": 19.7245,
      "step": 2890
    },
    {
      "epoch": 9.46078431372549,
      "grad_norm": 0.26505452394485474,
      "learning_rate": 1.6578689199958753e-07,
      "loss": 19.787,
      "step": 2895
    },
    {
      "epoch": 9.477124183006536,
      "grad_norm": 0.6489607691764832,
      "learning_rate": 1.5597579314952872e-07,
      "loss": 19.7944,
      "step": 2900
    },
    {
      "epoch": 9.477124183006536,
      "eval_loss": 5.199316501617432,
      "eval_runtime": 34.2686,
      "eval_samples_per_second": 3.969,
      "eval_steps_per_second": 0.496,
      "step": 2900
    },
    {
      "epoch": 9.493464052287582,
      "grad_norm": 0.6568999290466309,
      "learning_rate": 1.464616415230702e-07,
      "loss": 19.8537,
      "step": 2905
    },
    {
      "epoch": 9.509803921568627,
      "grad_norm": 0.3786371052265167,
      "learning_rate": 1.3724472411675517e-07,
      "loss": 19.752,
      "step": 2910
    },
    {
      "epoch": 9.526143790849673,
      "grad_norm": 2.2262725830078125,
      "learning_rate": 1.2832531896098788e-07,
      "loss": 19.849,
      "step": 2915
    },
    {
      "epoch": 9.542483660130719,
      "grad_norm": 0.7104278206825256,
      "learning_rate": 1.1970369511165035e-07,
      "loss": 19.8275,
      "step": 2920
    },
    {
      "epoch": 9.558823529411764,
      "grad_norm": 2.1221837997436523,
      "learning_rate": 1.1138011264198001e-07,
      "loss": 19.6809,
      "step": 2925
    },
    {
      "epoch": 9.57516339869281,
      "grad_norm": 1.2895063161849976,
      "learning_rate": 1.0335482263473028e-07,
      "loss": 19.7478,
      "step": 2930
    },
    {
      "epoch": 9.591503267973856,
      "grad_norm": 0.37538477778434753,
      "learning_rate": 9.562806717459572e-08,
      "loss": 19.6931,
      "step": 2935
    },
    {
      "epoch": 9.607843137254902,
      "grad_norm": 0.19342906773090363,
      "learning_rate": 8.82000793409088e-08,
      "loss": 19.7783,
      "step": 2940
    },
    {
      "epoch": 9.624183006535947,
      "grad_norm": 1.047847032546997,
      "learning_rate": 8.107108320060675e-08,
      "loss": 19.9061,
      "step": 2945
    },
    {
      "epoch": 9.640522875816993,
      "grad_norm": 0.5270260572433472,
      "learning_rate": 7.424129380147471e-08,
      "loss": 19.863,
      "step": 2950
    },
    {
      "epoch": 9.640522875816993,
      "eval_loss": 5.200392723083496,
      "eval_runtime": 34.1743,
      "eval_samples_per_second": 3.98,
      "eval_steps_per_second": 0.497,
      "step": 2950
    },
    {
      "epoch": 9.656862745098039,
      "grad_norm": 3.3829193115234375,
      "learning_rate": 6.771091716566091e-08,
      "loss": 19.7652,
      "step": 2955
    },
    {
      "epoch": 9.673202614379084,
      "grad_norm": 0.5827475786209106,
      "learning_rate": 6.148015028345833e-08,
      "loss": 19.7415,
      "step": 2960
    },
    {
      "epoch": 9.68954248366013,
      "grad_norm": 0.4943353235721588,
      "learning_rate": 5.5549181107362734e-08,
      "loss": 19.6424,
      "step": 2965
    },
    {
      "epoch": 9.705882352941176,
      "grad_norm": 0.26524120569229126,
      "learning_rate": 4.991818854640396e-08,
      "loss": 19.8085,
      "step": 2970
    },
    {
      "epoch": 9.722222222222221,
      "grad_norm": 1.1838527917861938,
      "learning_rate": 4.458734246075236e-08,
      "loss": 19.8436,
      "step": 2975
    },
    {
      "epoch": 9.738562091503269,
      "grad_norm": 0.9788921475410461,
      "learning_rate": 3.9556803656588536e-08,
      "loss": 19.7688,
      "step": 2980
    },
    {
      "epoch": 9.754901960784313,
      "grad_norm": 0.47877246141433716,
      "learning_rate": 3.482672388125719e-08,
      "loss": 19.708,
      "step": 2985
    },
    {
      "epoch": 9.77124183006536,
      "grad_norm": 2.1873035430908203,
      "learning_rate": 3.039724581868631e-08,
      "loss": 19.7686,
      "step": 2990
    },
    {
      "epoch": 9.787581699346406,
      "grad_norm": 0.3162022531032562,
      "learning_rate": 2.6268503085089547e-08,
      "loss": 19.7867,
      "step": 2995
    },
    {
      "epoch": 9.803921568627452,
      "grad_norm": 0.7905992865562439,
      "learning_rate": 2.244062022492499e-08,
      "loss": 19.8711,
      "step": 3000
    },
    {
      "epoch": 9.803921568627452,
      "eval_loss": 5.199108600616455,
      "eval_runtime": 34.127,
      "eval_samples_per_second": 3.985,
      "eval_steps_per_second": 0.498,
      "step": 3000
    },
    {
      "epoch": 9.820261437908497,
      "grad_norm": 0.6512150168418884,
      "learning_rate": 1.8913712707149255e-08,
      "loss": 19.8455,
      "step": 3005
    },
    {
      "epoch": 9.836601307189543,
      "grad_norm": 0.5685052871704102,
      "learning_rate": 1.568788692172807e-08,
      "loss": 19.8315,
      "step": 3010
    },
    {
      "epoch": 9.852941176470589,
      "grad_norm": 1.2149546146392822,
      "learning_rate": 1.2763240176427715e-08,
      "loss": 19.8063,
      "step": 3015
    },
    {
      "epoch": 9.869281045751634,
      "grad_norm": 0.39952513575553894,
      "learning_rate": 1.0139860693880732e-08,
      "loss": 19.6727,
      "step": 3020
    },
    {
      "epoch": 9.88562091503268,
      "grad_norm": 0.24675464630126953,
      "learning_rate": 7.817827608924689e-09,
      "loss": 19.8549,
      "step": 3025
    },
    {
      "epoch": 9.901960784313726,
      "grad_norm": 0.5657869577407837,
      "learning_rate": 5.7972109662141065e-09,
      "loss": 19.7232,
      "step": 3030
    },
    {
      "epoch": 9.918300653594772,
      "grad_norm": 0.5921241641044617,
      "learning_rate": 4.0780717181077015e-09,
      "loss": 19.8123,
      "step": 3035
    },
    {
      "epoch": 9.934640522875817,
      "grad_norm": 4.356386661529541,
      "learning_rate": 2.660461722832075e-09,
      "loss": 19.8121,
      "step": 3040
    },
    {
      "epoch": 9.950980392156863,
      "grad_norm": 1.0303964614868164,
      "learning_rate": 1.5444237429140806e-09,
      "loss": 19.7439,
      "step": 3045
    },
    {
      "epoch": 9.967320261437909,
      "grad_norm": 0.31408587098121643,
      "learning_rate": 7.299914438929634e-10,
      "loss": 19.7257,
      "step": 3050
    },
    {
      "epoch": 9.967320261437909,
      "eval_loss": 5.1999101638793945,
      "eval_runtime": 34.4755,
      "eval_samples_per_second": 3.945,
      "eval_steps_per_second": 0.493,
      "step": 3050
    }
  ],
  "logging_steps": 5,
  "max_steps": 3060,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.43887881633792e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
